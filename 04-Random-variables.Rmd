# Random variables

::: goals
**Chapter goals**

In this chapter we will learn how to:

- Calculate and interpret the CDF and PDF of a random variable,
  or several random variables.
- Calculate and interpret the expected value of a discrete random 
  variable from its PDF.
- Calculate and interpret the variance and standard deviation of a 
  discrete random variable from its PDF.
- Work with common probability distributions including the Bernoulli,
  binomial, uniform and normal.
- Calculate and interpret the covariance and correlation coefficient of 
  two discrete random variables.
- Calculate and interpret conditional distributions and conditional
  expectations.
:::

## Introduction to random variables

In the previous chapter, we learned a framework for modeling random
outcomes events. In economics, the outcomes we are interested in are
usually quantitative, that is, they can be described by a number.
Quantitative outcomes are also called "random variables", and we 
have many tools for working with them.  

### What is a random variable?

A ***random variable*** is a number whose value depends
on a random outcome. The idea here is that we are going to use a random
variable to describe some (but not necessarily every) aspect 
of the outcome.

::: example
Returning to our roulette example, here are a few random variables we
could define:

- The original outcome $b$. 
- An indicator for whether a bet on red wins:
  $$r = I(b \in RED)=\begin{cases}1 & b \in RED\\ 0 & b \notin RED \\ \end{cases}$$
- The net payout from a \$1 bet on red:
      $$ w_{red} = w_{red}(b) = \begin{cases}  1 & \textrm{ if } b \in RED \\ -1 & \textrm{ if } b \in RED^c \end{cases} $$
      That is, a player who bets \$1 on red wins \$1 if the ball lands on red 
      and loses \$1 if the ball lands anywhere else.
- The net payout from a \$1 bet on 12:
      $$ w_{12} = w_{12}(b) = \begin{cases}  35 & \textrm{ if } b = 12 \\ -1 & \textrm{ if } b \neq 12 \end{cases} $$
      That is, a player who bets \$1 on 12 wins \$35 if the ball lands on 12 
      and loses \$1 if the ball lands anywhere else.

:::

A random variable can always be thought of as a function of the original
outcome. For convenience, we usually leave its dependence on the original
outcome implicit, and write it as if it were an ordinary variable.

### Probability distributions

A random variable has its own sample space (normally $\mathbb{R}$) 
and probability distribution.  This probability distribution can 
be derived from the probability distribution of the underlying outcome.

::: example
In our roulette example:

   - The probability distribution for $b$ is:
      $$\Pr(b = 0) = 1/37 \approx 0.027$$
      $$\Pr(b = 1) = 1/37 \approx 0.027$$
      $$\vdots$$
      $$\Pr(b = 36) = 1/37 \approx 0.027$$
      All other values of $b$ have probability zero.
   - The probability distribution for $w_{red}$ is:
      $$\Pr(w_{red} = 1) = \Pr(b \in RED) = 18/37 \approx 0.486$$
      $$\Pr(w_{red} = -1) = \Pr(b \notin RED) = 19/37 \approx 0.514$$
      All other values of $w_{red}$ have probability zero.
   - The probability distribution for $w_{12}$ is:
      $$\Pr(w_{12} = 35) = \Pr(b = 12) = 1/37 \approx 0.027$$
      $$\Pr(w_{12} = -1) = \Pr(b \neq 12) = 36/37 \approx 0.973$$
      All other values of $w_{12}$ have probability zero.

Notice that these random variables are related to each other since
they all depend on the same underlying outcome. We will talk later about how
to talk about those relationships.
:::

#### The support

The ***support*** of a random variable $x$ is the smallest[^1] set $S_x \subset \mathbb{R}$ such that $\Pr(x \in S_x) = 1$.  

[^1]: Technically, it is the smallest *closed* set, but let's ignore that for now.

In plain language the support is the set of all values in the sample space 
that have some chance of actually happening. 

::: example
In our roulette example:

  - The support of $b$ is $S_{b} = \{0,1,2,\ldots,36\}$.
  - The support of $w_{Red}$ is $S_{Red} = \{-1,1\}$.
  - The support of $w_{12}$ is $S_{12} = \{-1,35\}$.

:::

The random variables we have considered so far have  ***discrete*** support. That 
is, the support is a set of isolated points each of which has a strictly 
positive probability. But not all random variables have a discrete support. 
That will complicate the math quite a bit, as we will need to use calculus.

### The PDF and CDF

#### The PDF of a discrete random variable

We can describe the probability distribution of a random
variable with a function called its ***probability density function (PDF)*** .

The PDF of a discrete random variable is defined as:
  $$f_x(a) = \Pr(x = a)$$
where $a$ is any number.  By convention, we typically use a 
lower-case $f$ to represent a PDF, and we use the subscript to 
clarify which specific random variable we are talking about.

::: example
In our roulette example:
  $$f_b(a) = \Pr(b = a) = \begin{cases}
            1/37 & a \in \{0,1,\ldots,36\} \\
            0 & a \notin \{0,1,\ldots,36\} \\
          \end{cases}$$
  $$f_{red}(a) = \Pr(w_{red} = a) = \begin{cases}
            19/37 & a = -1 \\
            18/37 & a = 1 \\
            0 & a \notin \{-1,1\} \\
          \end{cases}$$
  $$f_{12}(a) = \Pr(w_{12} = a) = \begin{cases}
            36/37 & a = -1 \\
            1/37 & a = 35 \\
            0 & a \notin \{-1,35\} \\
          \end{cases}$$
Figure ??? below shows these three PDFs.
```{r PDF_all, echo = FALSE, fig.margin = TRUE, fig.cap = "PDFs for the roulette example"}
plot(x=0:36,
     y=rep(1/37,times=37),
     type="p",
     col="blue",
     xlab="a",
     ylab="f(a)",
     bty="l",
     xlim=c(-1,36),
     ylim=c(0,1),
     xaxp=c(-2,36,38),
     yaxp=c(0,1,4))
points(x=c(-1,1),y=c(19/37,18/37),col="red")
points(x=c(-1,35),y=c(36/37,1/37),col="green")
abline(h=1/37,lty=2,col="gray")
```
:::

We can calculate any probability from the PDF by simple addition.
  $$\Pr(x \in A) = \sum_{s \in S_x} f_x(s)I(s \in A)$$

::: example
In our roulette example:
  $$\Pr(b \leq 3) = \sum_{s=0}^{36}f_x(s)I(s \leq 3) = f_b(0) + f_b(1) + f_b(2) + f_b(3) = 4/37$$
  $$\Pr(b \in EVEN) = \sum_{s=0}^{36}f_x(s)I(s \in EVEN) = f_b(2) + f_b(4) + \cdots + f_b(36) = 18/37$$

:::

The PDF of a discrete random variable has several general properties:

  1. It is always between zero and one:
    $$0 \leq f_x(a) \leq 1$$
    since it is a probability.
  2. It sums up to one over the support:
    $$\sum_{a \in S_x} f_x(a) = \Pr(x \in S_x) = 1$$
    since the support has probability one by definition.
  3. It is strictly positive for all values in the support:
    $$a \in S_x \implies f_x(a) > 0$$
    since the support is the *smallest* set that has probability
    one.

We can prove these, but I will skip that.

#### The CDF

Another way to describe the probability distribution of a random
variable is with a function called its 
***cumulative distribution function (CDF)***. 
The CDF is a little less intuitive than the PDF, but it has
the advantage that it always has the same definition 
whether or not the random variable is discrete.

The CDF of the random variable $x$ is the 
function $F_x:\mathbb{R} \rightarrow [0,1]$ defined by:
  $$F_x(a) = Pr(x \leq a)$$
where $a$ is any number.  By convention, we typically use an upper-case
$F$ to indicate a CDF, and we use the subscript to indicate
what random variable we are talking about.

The CDF has several properties:

  1. It always lies between zero and one:
      $$0 \leq F_x(a) \leq 1$$
     since it is a probability.
  2. It starts at zero and ends at one:
      $$F_x(-\infty) = \Pr(x \leq -\infty) = 0$$
      $$F_x(\infty) = \Pr(x \leq \infty) = 1$$
  2. It is non-decreasing.  That is, for any $a_1 \leq a_2$
      $$F_x(a_1) \leq F_x(a_2)$$
     This is because the event $x \leq a_2$ implies the event $x \leq a_1$,
     so it must be at least as probable.
  3. For any $a_1 < a_2$,
      $$\Pr(a_1 < x \leq a_2) = F_x(a_2) - F_x(a_1)$$

As I said earlier, the CDF is well-defined and has these properties
whether $x$ is discrete or continuous. 

If a random variable is discrete, we can construct its CDF
by just adding up the PDF:
  $$F_x(a) = \Pr(x \leq a) = \sum_{s \in S_x} f_x(s)I(s \leq a)$$
We can also construct the PDF from the CDF.  Pick some positive but
small number $\epsilon$.  Then:
  $$f_x(a) = F_x(a) - F_x(a-\epsilon)$$
as long as $\epsilon$ is small enough.

::: example
In our roulette example:

  - The CDF of $b$ is:
     $$F_b(a) = \begin{cases}
                   0 & a < 0 \\
                   1/37 & 0 \leq a < 1 \\
                   2/37 & 1 \leq a < 2 \\
                   \vdots & \vdots \\
                   36/37 & 35 \leq a < 36 \\
                   1 & a \geq 36 \\
                \end{cases}$$
  - The CDF of $w_{red}$ is:
    $$F_{red}(a) = \begin{cases}
                0 & a < -1 \\
                19/37 & -1 \leq a < 1 \\
                1 & a \geq 1 \\
                \end{cases}$$
  - The CDF of $w_{12}$ is:
    $$F_{12}(a) = \begin{cases}
                0 & a < -1 \\
                36/37 & -1 \leq a < 35 \\
                1 & a \geq 35 \\
                \end{cases}$$

Figure ??? below graphs these CDFs. 
```{r CDF_all, echo = FALSE, fig.margin = TRUE, fig.cap = "CDFs for the roulette example"}
plot(x=c(-40,-1,1,40),
     y=c(0,19/37,1,1)-0.001,
     type="s",
     col="red",
     xlab="a",
     ylab="F(a)",
     bty="l",
     xaxp=c(-40,40,10),
     yaxp=c(0,1,2))
lines(x=c(-40,seq(from=0,to=36,by=1),40),
      y=c(0,seq(from=0,to=1,length=37),1)+0.001,
      type="s",
      col="green")
lines(x=0.1+ c(-40,-1,35,40),
      y=0.01+c(0,36/37,1,1),
      type="s",
      col="blue")
abline(h=0.5,lty=2,col="gray")
```
Notice that they show all of the general properties described above. In 
addition, they all have a distinctive "stair-step" shape, jumping up at 
each point in $S_x$ and flat between those points,  This is a general 
property of CDFs for discrete random variables.
:::


#### Continuous random variables

So far we have considered random variables with a discrete support. However,
many random variables of interest have a continuous support: they can
take on *any* real value within some range. 

For example, Canada produced 31.251 million metric tons of wheat in 2019. If we
think of that number as a random variable, it's clear that this number
could have been 31.252 million metric tons if circumstances were different. It
also could have been any number between those numbers, for example 31.2511
million or 31.2517 million.

A ***continuous random variable*** has the property that the the probability
of any specific value is zero:
  $$\Pr(x=a) = 0$$
Now this creates something of a paradox: by the rules of probability
the probability that $x$ takes on *some* value is $\Pr(x \in \mathbb{R}) = 1$
but the probability that $x$ takes on any *specific* value is zero.
How can this work?

I'll explain how it works with an example.  

::: example
**The standard uniform distribution**

Consider a random variable $x$ that has the ***standard uniform*** 
distribution. What that means is that:

1. The support of $x$ is the range $[0,1]$.
2. All values in this range are equally likely.

The CDF of the standard uniform distribution is:
  $$F_x(a) = \Pr(x \leq a) = \begin{cases} 0 & a < 0 \\ a & a \in [0,1] \\1 & a > 1 \\ \end{cases}$$
Figure ??? below shows the CDF of the standard uniform distribution. 
```{r CDF_uniform, echo = FALSE}
plot(x=seq(from=-2,to=2,length.out=100),y=punif(seq(from=-2,to=2,length.out=100)),type="l",xlab="a",ylab=expression(Pr(x <= a)),bty="l",xaxp=c(-2,2,10),yaxp=c(0,1,2))
abline(h=0.5,lty=2,col="gray")
```
In all of the discrete examples we have considered so far, the CDF rises in 
a "stair-step" manner: a series of alternating vertical jumps and 
flat spots. In contrast, the standard uniform CDF rises continuously with
no jumps.  All continuous random variables have a CDF with this property.

Let $a_1$ and $a_2$ be any two numbers between 0 and 1, and let $a_1 < a_2$.
Then the probability of $x$ being between $a_1$ and $a_2$ is:
  $$\Pr(a_1 < x \leq a_2) = F_x(a_2) - F_x(a_1) = a_2 - a_1$$
As $a_2$ gets closer and closer to $a_1$ this number gets closer and closer
to zero, so the probability of $x$ being *exactly* $a_1$ is zero.
:::

The PDF of a continuous random variable is defined as:
  $$f_x(a) = \frac{dF_x(a)}{da}$$
  
::: example
The PDF of a standard uniform random variable is:
  $$f_x(a) = \begin{cases} 0 & a < 0 \\ 1 & a \in [0,1] \\ 0 & a > 1 \\ \end{cases}$$
which looks like this:
```{r PDF_uniform, echo = FALSE}
plot(x=seq(from=-2,to=2,length.out=1000),y=dunif(seq(from=-2,to=2,length.out=1000)),type="l",xlab="a",ylab=expression(Pr(x <= a)),bty="l",xaxp=c(-2,2,10),yaxp=c(0,1,2))
```
:::

Now, in order to work with continuous random variables we would need to
use integral calculus. Integral calculus is taught in MATH 158, which 
is not a prerequisite for the course, So:

  - Most of my examples will be for discrete case.
  - I will briefly show you the math for the continuous case, 
    but I will not expect you to do it.
  - Most of the results I give you will apply for both cases.

::: fyi
**Integral calculus for continuous random variables**
I have defined PDF based on the CDF, but we can also go the other way.  That
is, if we know the PDF we can calculate the CDF:
  $$F_x(a) = \int_{-\infty}^a f_x(v)dv$$
More generally the probability of $x$ being between any two numbers is:
  $$\Pr(a \leq x \leq b) = F_x(b) - F_x(a) = \int_a^b f_x(v)dv$$
Since most of you don't know integral calculus, you probably have 
no idea what this is or how to solve it.  That's OK!  All you need
to know is that it can be solved.
:::

#### Modes

Roughly speaking, the ***mode*** of a random variable is its most likely 
value (i.e., the value with the highest PDF).

:::example
In our roulette example:

 - The mode of $w_{red}$ is $-1$. That is, losing \$1 is the 
    most likely outcome.
 - The mode of $w_{12}$ is also $-1$.

What is the mode of $b$, since it takes on one of 37 equally-likely values?
In order to answer that, we would need to define the mode more precisely than
just "the most likely outcome." But this is an introductory course,
so let's just leave it at that.
:::

#### Medians, quantiles and percentiles

Roughly speaking, the ***median*** of a random variable is the value in the 
"middle"of the distribution, i.e., we have the same probability of being 
above the median as we do of being below the median.
 
As with the mode, this simple definition works fine in some cases but not
others. But in this case, let's fine-tune the definition so it always works.

We will start by defining something more general called a ***quantile*** or
***percentile***.  Let $x$ be a random variable with CDF $F_x$, and let
$\alpha$ be any number between zero and one.  Then the $\alpha$ quantile
of $x$ is defined as:

$$q_a(x) = \min\{a: \Pr(x \leq a) \geq \alpha\} = \min\{a: F_x(a) \geq \alpha\}$$
The $\alpha$ quantile of a distribution is also called the $100*\alpha$
percentile; for example the 0.25 quantile of $x$ is also called the 25th
percentile of $x$.

::: example
In our roulette example: 
  $$F_{red}(a) = \begin{cases}0 & a < -1 \\ 0.514 & -1 \leq a < 1 \\ 1 & a \geq 1 \\ \end{cases}$$ 
the 0.25 quantile (25th percentile) of $w_{red}$ is:
  $$q_{0.25}(w_{red}) = \min\{a: \Pr(w_{red} \leq a) \geq 0.25\} = \min [-1,1] = -1$$
the 0.5 quantile (50th percentile) of $w_{red}$ is:
  $$q_{0.5}(w_{red}) = \min\{a: \Pr(w_{red} \leq a) \geq 0.5\} = \min [-1,1] = -1$$
and the 0.75 quantile (75th percentile) is:
  $$q_{0.75}(w_{red}) = \min\{a: \Pr(w_{red} \leq a) \geq 0.75\} = \min\{1\} = 1$$
:::

Having precisely defined quantiles and percentiles, we can now precisely
define the median: the median is the 0.5 quantile or 50th percentile.


::: example
In our roulette example, the median is:
  $$median(w_{red}) = q_{0.5}(w_{red}) = -1$$
:::


### The expected value

Both the median and mode are often interpreted as measures of a random variable's
"central tendency", or as predictions of its "typical" value. The expected 
value (also called the mean) is another measure of central tendency. 

#### Definition of expected value

The ***expected value*** or ***mean*** of a random variable $x$ is written
$E(x)$. When $x$ is discrete, it is defined as:

$$E(x) = \sum_{a \in S_x} a\Pr(x=a) = \sum_{a \in S_x} af_x(a)$$
We can think of the expected value as weighted average of the possible values in the support, with weights equal to the probability of observing that value.


::: example
In our roulette example:
  $$E(b) = 0*\underbrace{f_b(0)}_{1/37} + 1*\underbrace{f_b(1)}_{1/37} + \cdots 36*\underbrace{f_b(36)}_{1/37} = 18$$
    $$E(w_{red}) = -1*\underbrace{f_{red}(-1)}_{19/37} + 1*\underbrace{f_{red}(1)}_{18/37} \approx -0.027$$
    $$E(w_{12}) = -1*\underbrace{f_{12}(-1)}_{36/37} + 35*\underbrace{f_{12}(35)}_{1/37} \approx -0.027$$
That is, each dollar bet on red leads to an average loss of 2.7 cents for the bettor, as does each dollar bet on 12.
:::

::: fyi
**The expected value for a continuous random variable**

When $x$ is continuous, its expected value is defined as:
  $$E(x) = \int_{-\infty}^{\infty} af_x(a)da$$
Notice that this looks just like the definition for the discrete case, but
with the sum replaced by an integral sign. 

There is even a general definition that covers both discrete
and continuous variables, as well as any mix between them:
  $$E(x) - \int_{-\infty}^{\infty} a dF_x(a)$$
Again, I do not expect you to understand, remember, or use 
either of these definitions, only to know that they exist.
:::


#### Properties of the expected value

In addition to taking the expected value of $x$, we can also take the
expected value of any function of $x$:
  $$E(g(x)) = \sum_{s \in S_x} g(s)\Pr(x = s) = \sum_{s \in S_x} g(s)f_x(s)$$
Now, remember that the expected value is a sum, and so it has some 
of the same properties as sums. In particular, the associative and
distributive rules apply, which means:
  $$E(a + bx) =  a + bE(x)$$
That is, we can take the expected value "inside" any linear function.
This will turn out to be a very handy property.

Unfortunately, this handy property applies only to linear functions. If
$g(\cdot)$ is not a linear function than $E(g(x)) \neq g(E(x))$. For 
example:
  $$E(x^2) \neq E(x)^2$$
  $$E( 1/x ) \neq 1 / E(x)$$
Students frequently make this mistake, so try to avoid it.

::: example
Suppose we bet \$100 on red.  Our net payout will be $100 \, w_{red}$
so our expected payout will be:
  $$E(100 \, w_{red}) = 100 \, E(w_{red}) = 100*(-0.027) = -2.7$$
In other words, the average result of a \$100 bet on red is a loss
of \$2.70.
:::

### Variance and standard deviation

The ***variance*** of a random variable $x$ is defined as:
$$\sigma_x^2 = var(x) = E((x-E(x))^2)$$
The ***standard deviation*** of a random variable 
is defined as the square root of its variance.
$$\sigma_x = sd(x) = \sqrt{var(x)}$$
Both variance and standard deviation can be thought of as 
measures of how much $x$ tends to deviate from its central
tendency $E(x)$. 

::: example
The variance of $r$ is:
  $$var(r) = (0-\underbrace{E(r)}_{18/37})^2 *\frac{19}{37} + (1-\underbrace{E(r)}_{18/37})^2 * \frac{18}{37} \approx 0.25$$
and its standard deviation is:
  $$sd(r) = \sqrt{var(r)} \approx 0.5$$ 

The variance of $w_{red}$ is:
  $$var(w_{red}) = (-1-\underbrace{E(w_{red})}_{\approx 0.027})^2 * \frac{19}{37} + (1-\underbrace{E(w_{red})}_{\approx 0.027})^2 * \frac{18}{37} \approx 1.0$$
and its standard deviation is
  $$sd(w_{red}) = \sqrt{var(w_{red})} \approx 1.0$$ 
The variance of $w_{12}$ is 
  $$var(w_{12}) = (-1-\underbrace{E(w_{12})}_{\approx 0.027})^2 * \frac{36}{37} + (35-\underbrace{E(w_{12})}_{\approx 0.027})^2 * \frac{1}{37} \approx 34.1$$
and its standard deviation is
  $$sd(w_{12}) = \sqrt{var(w_{12})} \approx 5.8$$ 
That is, a bet on 12 has the same expected payout as a bet on red, but
the payout is much more variable.
:::

The variance and standard deviation have several standard properties:
  
- They are always non-negative:
  $$var(x) \geq 0$$
  $$sd(x) \geq 0$$
- For any constants $a$ and $b$:
  $$var(a +bx) = b^2 var(x)$$
  $$sd(a +bx) = b sd(x)$$
- The variance can be written as:
  $$var(x) = E(x-E(x))^2 = E(x^2) - E(x)^2$$

We can easily derive these properties but we will skip that now.

### Standard distributions

Some probability distributions appear so often in applications that
we have given them names. We will go through a few of the most 
important ones below.

#### Discrete uniform

The ***discrete uniform*** distribution is a distribution with 
that puts equal probability on every value in a discrete set 
$S_x$. Its PDF is:
$$f_x(a) = \begin{cases}
          1/|S_x| & a \in S_x \\
          0 & a \notin S_x \\
          \end{cases}$$
Discrete uniform distributions appear in gambling and similar 
applications.  

::: example
In our roulette example, the outcome $b$ has a discrete 
uniform distribution on $\Omega = \{0,1,\ldots,36\}$.
:::

#### Bernoulli

The ***Bernoulli*** probability distribution is usually written:
$$x \sim Bernoulli(p)$$
It has discrete support $S_x = \{0,1\}$ and PDF:
$$f_x(a) = \begin{cases} (1-p) & a = 0 \\ p & a = 1 \\ 0 & a = \textrm{anything else}\\ \end{cases}$$
We typically use Bernoulli random variables to model the probability of some
event.

The mean and variance are:
$$E(x) = (1-p)*0 + p*1 = p$$
$$var(x) = E[(x-E(x))^2] = E[(x-p)^2] = (1-p)(0-p)^2 + p(1-p)^2 = p(1-p)$$

::: example
In our roulette example, $r$ has the $Bernoulli(18/37)$ distribution.
:::

#### Binomial

The ***binomial*** probability distribution is usually written:
$$x \sim Binomial(n,p)$$
It has discrete support $S_x = \{0,1,2,\ldots,n\}$ and its PDF is:
$$f_x(a) = 
  \begin{cases} 
    \frac{n!}{a!(n-a)!} p^a(1-p)^{n-a} & a \in S_x \\ 
    0 & \textrm{anything else} \\ 
  \end{cases}$$
The binomial distribution is typically used to model frequencies or counts.

Let $(b_1,b_2,\ldots,b_n)$ be a sequence of $n$ independent random 
variables from the $Bernoulli(p)$ distribution and let:
  $$x = \sum_{i=1}^n b_i$$
count up the number of times that $b_i$ is equal to one (i.e., the event
modeled by $b_i$ happened).  Then it is possible to derive the
distribution for $y$, and it turns out to be $Binomial(n,p)$.

I won't derive the formula for the binomial PDF, but the intuition
is simple: $\frac{n!}{a!(n-a)!}$ is the number of outcomes in 
which $x=a$ and the $p^a(1-p)^{n-a}$ is the probability 
of each of those outcomes.

The mean and variance of a binomial random variable are:
  $$E(x) = np$$
  $$var(x) = np(1-p)$$

::: example
Suppose we play 50 games of roulette, and bet on red in every game.
Let $WIN50$ be the number of times we win.  Since the outcome
of a single bet on red is $r \sim Bernoulli(18/37)$, this means
that $WIN50$ has the $Binomial(50,18/37)$ distribution.
:::

#### Uniform and standard uniform

The ***uniform*** probability distribution is usually written
$$x \sim U(L,H)$$
where $L < H$. It is a continuous probability distribution with 
support $S_x = [L,H]$ and PDF:
$$f_x(a) = \begin{cases}\frac{1}{H-L} & a \in S_x \\ 0 & \textrm{otherwise} \\ \end{cases}$$
The uniform distribution puts equal probability on all values between $L$ 
and $H$. We have already seen the ***standard uniform*** distribution,
which is just the $U(0,1)$ distribution.

::: fyi
Uniform distributions are commonly used by computers because:

- It is easy for a computer to generate a random number from the standard 
  uniform distribution.
- You can generate a random variable with any probability distribution 
  you like by following these steps:
    1. Generate a random variable $w \sim U(0,1)$.
    2. Calculate $x = F^{-1}(w)$ where $F^{-1}$ is the inverse CDF of 
      the distribution you want.

Every video game you have ever played is constantly generating
$U(0,1)$ random numbers and using them to determine the behavior of non-player
characters, the location of resources, etc.  Without that element of randomess,
these games would be way too predictable to be much fun.
:::

The mean and variance of the $U(L,H)$ distribution are:
  $$E(x) = \frac{L+H}{2}$$
  $$var(x) = \frac{(H-L)^2}{12}$$

#### Normal and standard normal

The ***normal distribution*** or ***Gaussian distribution***
is typically written as:
$$ x \sim N(\mu,\sigma^2)$$ 
It is a continuous distribution with support $S_x = \mathbb{R}$
and PDF:
$$f_x(a) = \frac{1}{\sigma \sqrt{2\pi}} e^{-\frac{(a-\mu)^2}{2\sigma}}$$
The normal distribution looks strange, but it turns out to be a very 
important one in statistics for two reasons:

  1. Any linear function of a normally distributed random variable 
    is also normally distributed.  That is, suppose that 
    $x \sim N(\mu,\sigma^2)$ and let $y = a + bx$.  Then 
    $y \sim N(a+b\mu,b^2\sigma^2)$.
  2. A very important result called the Central Limit Theorem tells
      us that many random variables have a distribution that is
      well-approximated by the normal distribution. We will discuss 
      this in much more detail later.

The mean and variance of a $N(\mu,\sigma^2)$ random variable are:
$$E(x) = \mu$$
$$var(x) = \sigma^2$$

The $N(0,1)$ distribution is also called the ***standard normal distribution***
The standard normal distribution is so useful that we have special
symbol for its PDF:
  $$\phi(a) = \frac{1}{\sqrt{2\pi}} e^{-\frac{a^2}{2}}$$
and its CDF:
  $$\Phi(a) = \int_{-\infty}^a \phi(b)db$$
The standard normal CDF $\Phi(.)$ does not have a closed form
solution, but is easy to calculate on a computer.

Why is this useful?  Well remember that linear functions of 
normal random variables are also normal.  Then if $x \sim N(\mu,\sigma^2)$
$$ z = \frac{x-\mu}{\sigma} \sim N(0,1)$$
which implies:
$$F_x(a) = \Pr\left(x \leq a\right) = \Pr\left( \frac{x-\mu}{\sigma} \leq \frac{a-\mu}{\sigma}\right) = \Pr\left( z \leq \frac{a-\mu}{\sigma}\right) = \Phi\left(\frac{a-\mu}{\sigma}\right)$$
In other words, we can use the standard normal CDF to calculate the
CDF of any normally distributed random variable.

## Multiple random variables

We will often be interested in the relationship between two or more
random variables. For example, we might want to know how tax rates
are related to economic growth, or how education is related to 
income.

### Joint distributions

Let $x = x(b)$ and $y = y(b)$ be two random variables
defined in terms of the same underlying outcome $b$.
Their joint probability distribution assigns a probability
to every event that can be defined in terms of $x$ and $y$,
for example $\Pr(x = 6 \cap y = 0)$ or $\Pr(x < y)$.

This joint distribution can be fully described by the 
***joint CDF***
$$F_{x,y}(a,b) = \Pr(x \leq a \cap y \leq b)$$
It can also be described by the ***joint PDF***
$$f_{x,y}(a,b) = \begin{cases}
      \Pr(x = a \cap y = b) & \textrm{if $x$ and $y$ are discrete} \\
      \frac{\partial F_{x,y}(a,b)}{\partial a \partial b} & \textrm{if $x$ and $y$ are continuous} \\
      \end{cases}$$

The joint distribution tells you about the relationship between the
two variables as well as the characteristics of the variables themselves.
That is, we can always get the ***marginal*** distributions from the 
joint distributions:
$$F_x(a) = \Pr(x \leq a) = \Pr(x \leq a \cap y \leq \infty) = F_{x,y}(a,\infty)$$
$$F_y(b) = \Pr(y \leq n) = \Pr(x \leq \infty \cap y \leq b) = F_{x,y}(\infty,b)$$
but it is not possible to get the joint distribution from the marginal
distributions.

::: example
In our roulette example, the joint PDF of $w_{red}$ and 
$w_{12}$ can be derived from the original outcome.

If $b=12$, then both red and 12 win:
  $$f_{red,12}(1,35) = \Pr(w_{red}=1 \cap w_{12} = 35 = \Pr(b \in \{12\}) = 1/37$$
If $b \in RED$ but $b \neq 12$, then red wins but 12 loses:
  $$f_{red,12}(1,-1) = \Pr(b \in \{1,3,5,7,9,14,16,18,19,21,23,25,27,30,32,34,36\}) = 17/37$$
Otherwise both red and 12 lose:
  $$f_{red,12}(-1,-1) = \Pr(b \in \{0,2,4,6,7,10,11,13,15,17,20,22,24,26,28,31,33,35\}) = 19/37$$
All other values have probability zero.
:::

### Conditional distributions

Having defined joint distributions, we can now define conditional 
distributions. By the definition of a conditional probability:
$$\Pr(x \in A| y \in B) = \frac{\Pr(x \in A \cap y \in B)}{\Pr(y \in B)}$$
So we can define the conditional CDF:
  $$F_{y|x}(a,b) = \Pr(y \leq a|x=b)$$
Conditional distributions can be derived from the joint distribution,
but it isn't always easy.

::: example
In our roulette example, let's find the conditional PDF of the payout
for a bet on 12 given the payout for a bet on red. 
  $$\Pr(w_{12}=-1|w_{red}=-1) = \frac{\Pr(w_{12}=-1 \cap w_{red}=-1)}{\Pr(w_{red}=-1)}=\frac{19/37}{19/37} = 1$$
  $$\Pr(w_{12}=35|w_{red}=-1) = \frac{\Pr(w_{12}=35 \cap w_{red}=-1)}{\Pr(w_{red}=-1)}=\frac{0}{19/37} = 0$$
  $$\Pr(w_{12}=-1|w_{red}=1) = \frac{\Pr(w_{12}=-1 \cap w_{red}=1)}{\Pr(w_{red}=1)}=\frac{17/37}{18/37} \approx 0.944$$
  $$\Pr(w_{12}=35|w_{red}=1) = \frac{\Pr(w_{12}=35 \cap w_{red}=1)}{\Pr(w_{red}=1)}=\frac{1/37}{18/37} \approx 0.056$$
:::

### Independence

We say that $x$ and $y$ are ***independent*** if every event defined in 
terms of $x$ is independent of every event defined in terms of $y$.
  $$\Pr(x \in A \cap y \in B) = \Pr(x \in A)\Pr(y \in B)$$
Independence allows us to write all joint and conditional probabilities
in terms of marginal probabilities:
  $$F_{x,y}(a,b) = F_x(a)F_y(b)$$
  $$F_{y|x}(a,b) = F_y(a)$$
This is very handy, but remember: independence is an *assumption* that
we can only make when it's reasonable to do so.

::: example
In our roulette example, the winnings from a bet on red ($w_{red}$) and
the winnings from a bet on 12 ($w_{12}$) in the same game
are *not* independent. However the winnings from a bet on red and
a bet on 12 in two different games *are* independent since the
underlying outcomes are independent.
:::

### Covariance and correlation

We can take the expected value of any function of $x$ and $y$.
When $x$ and $y$ are both discrete:
  $$E(g(x,y)) = \sum_{a \in S_x} \sum_{b \in S_y} g(a,b)\Pr( x=a \cap y = b)$$
and when they are both continuous:
  $$E(g(x,y)) = \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} g(a,b)f_{x,y}(a,b)dadb$$
As with a single random variable, you can take the expected value inside
a linear function:
  $$E(ax + by + c) = aE(x) + bE(y) + c$$
but not inside most other functions.  For example:
  $$E(xy) \neq E(x)E(y)$$
  $$E(x/y) \neq E(x)/E(y)$$
etc.

::: example
Suppose we go to the roulette table and bet \$100 on red
and \$10 on 12. Our net payout is:
  $$w_{total} = 100*w_{red} + 10*w_{12}$$
which has expected value:
  $$E(c) = E(100 w_{red} + 10 w_{12}) = 100 \, \underbrace{E(w_{red})}_{\approx -0.027} + 10 \, \underbrace{E(w_{12})}_{\approx -0.027} \approx -3 $$
That is we expect this betting strategy to lose an average of 
about \$3 per game.
:::

The ***covariance*** of two random variables $x$ and $y$ 
is defined as:
$$\sigma_{xy} = cov(x,y) = E[(x-E(x))*(y-E(y))]$$
and their ***correlation*** is defined as:
$$\rho_{xy} = corr(x,y) = \frac{cov(x,y)}{\sqrt{var(x)var(y)}} = \frac{\sigma_{xy}}{\sigma_x\sigma_y}$$
Both the covariance and correlation are measures of how $x$ and $y$ tend to 
move together.  Positive correlation means that they tend to move in the same 
direction: above-normal values of $x$ tend to conicide with above-normal 
values of $y$.  Negative correlation means that they tend 
to move in opposite directions: above-normal values of $x$ tend to coincide
with below-normal values of $y$.

::: example
The covariance of $w_{red}$ and $w_{12}$ is:
  $$cov(w_{red},w_{12}) = 
    (1-\underbrace{E(w_{red})}_{\approx -0.027})(35-\underbrace{E(w_{12})}_{\approx -0.027})\underbrace{f_{red,12}(1,35)}_{1/37} 
    + (1-\underbrace{E(w_{red})}_{\approx -0.027})(-1-\underbrace{E(w_{12})}_{\approx -0.027})\underbrace{f_{red,12}(1,-1)}_{17/37} 
    + (-1-\underbrace{E(w_{red})}_{\approx -0.027})(-1-\underbrace{E(w_{12})}_{\approx -0.027})\underbrace{f_{red,12}(-1,-1)}_{19/37} \approx 0.999 $$
and its correlation is:
  $$corr(w_{red},w_{12}) = \frac{cov(w_{red},w_{12})}{\sqrt{var(w_{red})*var(w_{12})}} \approx \frac{0.999}{\sqrt{1.0*34.1}} \approx 0.17$$
:::

A few results:

- The covariance can be written:
  $$cov(x,y) = E(xy) - E(x)E(y)$$
- The variance of a random variable is its covariance with itself:
  $$cov(x,x) = var(x)$$
- Covariances are products, so:
  $$cov(ax+by+c, dx+ey+f) = ad \, var(x) + be \, var(y) + (bd + ae) \, cov(x,y)$$
- The variance of a sum is:
  $$var(ax+by+c) = a^2 \, var(x) + b^2 \, var(y) + 2ab \, cov(x,y)$$ 
- The correlation is always between -1 and 1:
  $$-1 \leq \rho_{xy} \leq 1$$
- If $x$ and $y$ are independent, then
  $$E(xy) = E(x)E(y)$$
  and
  $$cov(x,y) = corr(x,y) = 0$$
  Note that this does not go both ways; it is easy to find cases in which
  $cov(x,y) = 0$ but $x$ and $y$ are not independent.
