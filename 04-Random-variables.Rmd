# Introduction to random variables {#random-variables}

```{r setup4, include=FALSE}
knitr::opts_chunk$set(echo = FALSE,
                      prompt = FALSE,
                      tidy = TRUE,
                      collapse = TRUE)
library("tidyverse")
```

Chapter \@ref(probability-and-random-events) developed a general framework for
modeling random outcomes and events. This framework can be applied to
any set of random outcomes, no matter how complex.

However, many of the random outcomes we are interested in are quantitative,
that is, they can be described by a number. Quantitative outcomes 
are also called "random variables." In addition to the basic 
tools of probability developed in Chapter \@ref(probability-and-random-events),
we have some extremely useful specialized tools for random variables. This
chapter will develop these tools.

::: goals
**Chapter goals**

In this chapter we will learn how to:

- Calculate and interpret the CDF and PDF of a discrete random 
  variable, or several random variables.
- Calculate and interpret the expected value of a discrete random 
  variable from its PDF.
- Calculate and interpret the variance and standard deviation of a 
  discrete random variable from its PDF.
- Work with common discrete probability distributions including the 
  Bernoulli, binomial, and discrete uniform.
:::

## Introduction to random variables {#introduction-to-random-variables}

A ***random variable*** is a number whose value depends
on a random outcome. The idea here is that we are going to use a random
variable to describe some (but not necessarily every) aspect 
of the outcome.

::: example
**Random variables in roulette**

Here are a few random variables we could define in a roulette
game:

- The original outcome $b$. 
- An indicator for whether a bet on red wins:
  $$r = I(b \in Red)=\begin{cases}1 & b \in Red\\ 0 & b \notin Red \\ \end{cases}$$
- The net payout from a \$1 bet on red:
      $$ w_{red} = w_{red}(b) = \begin{cases}  1 & \textrm{ if } b \in Red \\ -1 & \textrm{ if } b \in Red^c \end{cases} $$
      That is, a player who bets \$1 on red wins \$1 if the ball lands on red 
      and loses \$1 if the ball lands anywhere else.
- The net payout from a \$1 bet on 14:
      $$ w_{14} = w_{14}(b) = \begin{cases}  35 & \textrm{ if } b = 14 \\ -1 & \textrm{ if } b \neq 14 \end{cases} $$
      That is, a player who bets \$1 on 14 wins \$35 if the ball lands on 14 
      and loses \$1 if the ball lands anywhere else.

All of these random variables are defined in terms of the underlying
outcome, but we can also define random variables in terms of other
random variables.  For example, we could have defined $w_{red}$
as $w_{red} = 2r-1$.
:::

A random variable is always a function of the original outcome, but
for convenience, we usually leave its dependence on the original
outcome implicit, and write it as if it were an ordinary variable.

### Probability distributions {#probability-distributions}

A random variable has its own sample space (normally $\mathbb{R}$) 
and probability distribution.  This probability distribution can 
be derived from the probability distribution of the underlying outcome.

::: example
**Probability distributions for roulette**

   - The probability distribution for $b$ is:
      $$\Pr(b = 0) = 1/37 \approx 0.027$$
      $$\Pr(b = 1) = 1/37 \approx 0.027$$
      $$\vdots$$
      $$\Pr(b = 36) = 1/37 \approx 0.027$$
      All other values of $b$ have probability zero.
   - The probability distribution for $w_{red}$ is:
      $$\Pr(w_{red} = 1) = \Pr(b \in Red) = 18/37 \approx 0.486$$
      $$\Pr(w_{red} = -1) = \Pr(b \notin Red) = 19/37 \approx 0.514$$
      All other values of $w_{red}$ have probability zero.
   - The probability distribution for $w_{14}$ is:
      $$\Pr(w_{14} = 35) = \Pr(b = 14) = 1/37 \approx 0.027$$
      $$\Pr(w_{14} = -1) = \Pr(b \neq 14) = 36/37 \approx 0.973$$
      All other values of $w_{14}$ have probability zero.

Notice that these random variables are related to each other since
they all depend on the same underlying outcome. Section
\@ref(multiple-random-variables) will explain how we can describe
and analyze those relationships.
:::

### The support {#the-support}

The ***support*** of a random variable $x$ is the smallest[^401] set $S_x \subset \mathbb{R}$ such that $\Pr(x \in S_x) = 1$.  

[^401]: Technically, it is the smallest *closed* set, but let's ignore that for now.

In plain language the support is the set of all values in the sample space 
that have some chance of actually happening. 

::: example
**The support in roulette**

The support is just the set of values with non-zero probability:

  - The support of $b$ is $S_{b} = \{0,1,2,\ldots,36\}$.
  - The support of $w_{Red}$ is $S_{Red} = \{-1,1\}$.
  - The support of $w_{14}$ is $S_{14} = \{-1,35\}$.

:::

The random variables we will consider in this chapter  have  ***discrete***
support. That is, the support is a set of isolated points each of which has
a strictly positive probability. In most examples the support will also have
a ***finite*** number of elements.  All finite sets are also discrete, but
it is also possible for a discrete set to have an infinite number of elements.
For example, the set of integers is both discrete and infinite.

Some random variables have a support that is continuous rather than 
discrete.  Chapter \@ref(more-on-random-variables) will cover continuous random variables. 

### The PDF and CDF {#the-pdf-and-cdf}

The PDF and CDF are both functions that allow us to describe the
probability distribution of a random variable.

#### The PDF of a discrete random variable {#the-pdf-of-a-discrete-random-variable}

We can describe the probability distribution of a random
variable with a function called its ***probability density function (PDF)***.

The PDF of a discrete random variable is defined as:
  $$f_x(a) = \Pr(x = a)$$
where $a$ is any number.  By convention, we typically use a 
lower-case $f$ to represent a PDF, and we use the subscript when needed
to clarify which specific random variable we are talking about.

::: example
**The PDF in roulette**

Our three random variables are all discrete, and each has its own
PDF:

  $$f_b(a) = \Pr(b = a) = \begin{cases}
            1/37 & a \in \{0,1,\ldots,36\} \\
            0 & a \notin \{0,1,\ldots,36\} \\
          \end{cases}$$
  $$f_{red}(a) = \Pr(w_{red} = a) = \begin{cases}
            19/37 & a = -1 \\
            18/37 & a = 1 \\
            0 & a \notin \{-1,1\} \\
          \end{cases}$$
  $$f_{14}(a) = \Pr(w_{14} = a) = \begin{cases}
            36/37 & a = -1 \\
            1/37 & a = 35 \\
            0 & a \notin \{-1,35\} \\
          \end{cases}$$
Figure \@ref(fig:RoulettePDF) below shows these three PDFs.

```{r RoulettePDF, fig.cap = "*PDFs for the roulette example*"}
RoulettePDF <- tibble(a = seq(from = -2, to= 36),
                      fb = c(0, 0, rep(1/37, times = 37)),
                      fred = c(0, 19/37, 0, 18/37, rep(0, times=35)),
                      f14 = c(0, 36/37,rep(0, times=35), 1/37, 0))
ggplot(data = RoulettePDF, mapping = aes(x = a)) +
  geom_point(aes(y=fb), col = "blue") +
  geom_point(aes(y=fred), col = "red") +
  geom_point(aes(y=f14), col = "green") +
  xlab("a") +
  ylab("f(a)") +
  geom_text(x = 4, 
            y = 4/37, 
            label = "f_b(a)", 
            col = "blue") +
  geom_text(x = 4, 
            y = 18/37, 
            label = "f_red(a)", 
            col = "red") +
  geom_text(x = 2, 
            y = 36/37, 
            label = "f_14(a)", 
            col = "green") +
  labs(title = "Probability density function (PDF)", 
       subtitle = "Roulette", 
       caption = "", 
       tag = "")
```
:::

We can calculate any probability from the PDF by simple addition. That
is:
  $$\Pr(x \in A) = \sum_{s \in S_x} f_x(s)I(s \in A)$$
where[^402] $A \subset \mathbb{R}$ is any event defined for $x$.

[^402]: If you are unfamiliar with the notation here, please refer to
Section \@ref(summations) in the Math Review Appendix.

::: example
**Some event probabilities in roulette**

Since the outcome in roulette is discrete, we can calculate
any event probability by adding up the probabilities of the
event's outcomes.

The probability of the event $b \leq 3$ can be calculated:
  \begin{align}
    \Pr(b \leq 3) &= \sum_{s=0}^{36}f_x(s)I(s \leq 3) \\
      &= f_b(0) + f_b(1) + f_b(2) + f_b(3) \\
      &= 4/37 
  \end{align}
  
The probability of the event $b \in Even$ can be calculated:
  \begin{align}
    \Pr(b \in Even) &= \sum_{s=0}^{36}f_x(s)I(s \in Even) \\
        &= f_b(2) + f_b(4) + \cdots + f_b(36) \\
        &= 18/37 
  \end{align}

:::

The PDF of a discrete random variable has several general properties:

  1. It is always between zero and one:
    $$0 \leq f_x(a) \leq 1$$
    since it is a probability.
  2. It sums up to one over the support:
    $$\sum_{a \in S_x} f_x(a) = \Pr(x \in S_x) = 1$$
    since the support has probability one by definition.
  3. It is strictly positive for all values in the support:
    $$a \in S_x \implies f_x(a) > 0$$
    since the support is the *smallest* set that has probability
    one.

We can prove these, but I will skip that.

#### The CDF {#the-cdf}

Another way to describe the probability distribution of a random
variable is with a function called its 
***cumulative distribution function (CDF)***. 
The CDF is a little less intuitive than the PDF, but it has
the advantage that it always has the same definition 
whether or not the random variable is discrete.

The CDF of the random variable $x$ is the 
function $F_x:\mathbb{R} \rightarrow [0,1]$ defined by:
  $$F_x(a) = Pr(x \leq a)$$
where $a$ is any number.  By convention, we typically use an upper-case
$F$ to indicate a CDF, and we use the subscript to indicate
what random variable we are talking about.

The CDF has several properties:

  1. It always lies between zero and one:
      $$0 \leq F_x(a) \leq 1$$
     since it is a probability.
  2. It starts at zero and ends at one:
      $$F_x(-\infty) = \Pr(x \leq -\infty) = 0$$
      $$F_x(\infty) = \Pr(x \leq \infty) = 1$$
  2. It is non-decreasing.  That is, for any $a_1 \leq a_2$
      $$F_x(a_1) \leq F_x(a_2)$$
     This is because the event $x \leq a_2$ implies the event $x \leq a_1$,
     so it must be at least as probable.
  3. For any $a_1 < a_2$,
      $$\Pr(a_1 < x \leq a_2) = F_x(a_2) - F_x(a_1)$$

We can construct the CDF of a discrete random variable by
just adding up the PDF:
  \begin{align}
    F_x(a) &= \Pr(x \leq a) \\
      &= \sum_{s \in S_x} f_x(s)I(s \leq a)
  \end{align}
This formula leads to a "stair-step" appearance: the CDF is flat for
all values outside of the support, and then jumps up at all values
in the support.

::: example
**CDFs for roulette**

  - The CDF of $b$ is:
     $$F_b(a) = \begin{cases}
                   0 & a < 0 \\
                   1/37 & 0 \leq a < 1 \\
                   2/37 & 1 \leq a < 2 \\
                   \vdots & \vdots \\
                   36/37 & 35 \leq a < 36 \\
                   1 & a \geq 36 \\
                \end{cases}$$
  - The CDF of $w_{red}$ is:
    $$F_{red}(a) = \begin{cases}
                0 & a < -1 \\
                19/37 & -1 \leq a < 1 \\
                1 & a \geq 1 \\
                \end{cases}$$
  - The CDF of $w_{14}$ is:
    $$F_{14}(a) = \begin{cases}
                0 & a < -1 \\
                36/37 & -1 \leq a < 35 \\
                1 & a \geq 35 \\
                \end{cases}$$

Figure \@ref(fig:RouletteCDF) below graphs these CDFs. 
```{r RouletteCDF, fig.cap = "*CDFs for the roulette example*"}
RouletteCDF <- RoulettePDF %>%
    mutate (Fb = cumsum(fb)) %>%
    mutate (Fred = cumsum(fred))%>%
    mutate (F14 = cumsum(f14)) 
ggplot(data = RouletteCDF, mapping = aes(x = a)) +
  geom_step(aes(y=Fb), col = "blue") +
  geom_step(aes(y=Fred), col = "red") +
  geom_step(aes(y=F14), col = "green") +
  xlab("a") +
  ylab("F(a)") +
  geom_text(x = 7, 
            y = 4/37, 
            label = "f_b(a)", 
            col = "blue") +
  geom_text(x = 5, 
            y = 18/37, 
            label = "f_red(a)", 
            col = "red") +
  geom_text(x = 8, 
            y = 32/37, 
            label = "f_14(a)", 
            col = "green") +
  labs(title = "Cumulative distribution function (CDF)", 
       subtitle = "Roulette", 
       caption = "", 
       tag = "")
```
Notice that they show all of the general properties described above. In 
addition, they all have a distinctive "stair-step" shape, jumping up at 
each point in $S_x$ and flat between those points,  This is a general 
property of CDFs for discrete random variables.
:::

We can also go the other way, and construct the PDF of a discrete random 
variable from its CDF. Each little jump in the CDF is a point in the support,
and the size of the jump is exactly equal to the PDF.

::: fyi
In more formal mathematics, the formula for deriving the PDF of a discrete
random variable from its CDF would be written:

  $$f_x(a) = \lim_{\epsilon \rightarrow 0} F_x(a) - F_x(a-|\epsilon|)$$
but we can just think of it as the size of the jump.
:::

## The expected value {#the-expected-value}

The ***expected value*** of a random variable $x$ is written
$E(x)$. When $x$ is discrete, it is defined as:

$$E(x) = \sum_{a \in S_x} a\Pr(x=a) = \sum_{a \in S_x} af_x(a)$$
The expected value is also called the ***mean***, the ***population mean***
or the ***expectation*** of the random variable.


::: example
**The expected value in roulette**

The expected value of $b$ is:
  $$E(b) = 0*\underbrace{f_b(0)}_{1/37} + 1*\underbrace{f_b(1)}_{1/37} + \cdots 36*\underbrace{f_b(36)}_{1/37} = 18$$
  
The expected value of $w_{red}$ is:
    $$E(w_{red}) = -1*\underbrace{f_{red}(-1)}_{19/37} + 1*\underbrace{f_{red}(1)}_{18/37} \approx -0.027$$
The expected value of $w_{14}$ is:
    $$E(w_{14}) = -1*\underbrace{f_{14}(-1)}_{36/37} + 35*\underbrace{f_{14}(35)}_{1/37} \approx -0.027$$
That is, each dollar bet on red leads to an average loss of 2.7 cents for the bettor, as does each dollar bet on 14.
:::

We can think of the expected value as a weighted average of its possible
values, with each value weighted by the probability of observing that value.

### Properties of the expected value {#properties-of-the-expected-value}

In addition to taking the expected value of $x$, we can also take the
expected value of any function of $x$:
  $$E(g(x)) = \sum_{s \in S_x} g(s)\Pr(x = s) = \sum_{s \in S_x} g(s)f_x(s)$$
Now, remember that the expected value is a sum, and so it has some 
of the same properties as sums. In particular, the associative and
distributive rules apply, which means:
  $$E(a + bx) =  a + bE(x)$$
That is, we can take the expected value "inside" any linear function.
This will turn out to be a very handy property.

Unfortunately, this handy property applies only to linear functions. If
$g(\cdot)$ is not a linear function than $E(g(x)) \neq g(E(x))$. For 
example:
  $$E(x^2) \neq E(x)^2$$
  $$E( 1/x ) \neq 1 / E(x)$$
Students frequently make this mistake, so try to avoid it.

::: example
**Using the linearity of the expected value**

Suppose we bet \$100 on red.  Our net payout will be $100w_{red}$
so our expected payout will be:
  $$E(100 w_{red}) = 100 \, E(w_{red}) = 100*(-0.027) = -2.7$$
In other words, the average result of a \$100 bet on red is a loss
of \$2.70.
:::


## Other properties of a random variable {#the-properties-of-a-random-variable}

The probability distribution of a random variable is fully described
by its PDF or CDF.  However, we will often be interested in 
describing the random variable with a few simple summary numbers.

For example, we might be interested in the most common value (also
called the mode), or we might be interested in a "typical" value,
or we might be interested in a simple measure of how much the 
random variable tends to vary.  All of these quantities
can be defined and calculated from on the PDF or CDF.

### Range {#range}

The ***range*** of a random variable is the interval from the
minimum value in its support to the maximum value in the support.

:::example
**The range in roulette**

- The range of $w_{red}$ is $[-1,1]$.
- The range of $w_{14}$ is $[-1,35]$.
- The range of $b$ is $[0,36]$.

:::

### Quantiles and percentiles {#quantiles-and-percentiles}

Let $x$ be a random variable with CDF $F_x$, and let
$\alpha$ be any number between zero and one.  Then the $\alpha$ ***quantile***
of $x$ is defined as:

$$q_a(x) = \min\{a: \Pr(x \leq a) \geq \alpha\} = \min\{a: F_x(a) \geq \alpha\}$$
The $\alpha$ quantile of a distribution is also called the $100*\alpha$
***percentile***; for example the 0.25 quantile of $x$ is also called the 25th
percentile of $x$.

::: example
**Quantiles in roulette**

The CDF of $w_{red}$ is:
  $$F_{red}(a) = \begin{cases}0 & a < -1 \\ 0.514 & -1 \leq a < 1 \\ 1 & a \geq 1 \\ \end{cases}$$ 
  
So its 0.25 quantile (25th percentile) is:
  $$q_{0.25}(w_{red}) = \min\{a: \Pr(w_{red} \leq a) \geq 0.25\} = \min [-1,1] = -1$$
its 0.5 quantile (50th percentile) is:
  $$q_{0.5}(w_{red}) = \min\{a: \Pr(w_{red} \leq a) \geq 0.5\} = \min [-1,1] = -1$$
and its 0.75 quantile (75th percentile) is:
  $$q_{0.75}(w_{red}) = \min\{a: \Pr(w_{red} \leq a) \geq 0.75\} = \min\{1\} = 1$$
:::


### Median {#the-median}

The ***median*** of a random variable is its 0.5 quantile or 50th percentile.  It can be interpreted roughly as the "middle" of the
distribution.

::: example
**The median in roulette**

The median of $w_{red}$ is just its 0.5 quantile or 50th percentile:
  $$median(w_{red}) = q_{0.5}(w_{red}) = -1$$
:::


### Variance {#variance-and-standard-deviation}

The median and expected value both aim to describe a typical
or central value of the random variable.  We are also interested in
measures of how much the random variable varies.  We have already
seen one - the range - but there are others, including the
variance and standard deviation.

The ***variance*** of a random variable $x$ is defined as:
$$\sigma_x^2 = var(x) = E((x-E(x))^2)$$
Variance can be thought of as a measure of how much $x$ tends to 
deviate from its central tendency $E(x)$. 

::: example
**Variance in roulette**

The variance of $r$ is:
  $$var(r) = (0-\underbrace{E(r)}_{18/37})^2 *\frac{19}{37} + (1-\underbrace{E(r)}_{18/37})^2 * \frac{18}{37} \approx 0.25$$

The variance of $w_{red}$ is:
  $$var(w_{red}) = (-1-\underbrace{E(w_{red})}_{\approx 0.027})^2 * \frac{19}{37} + (1-\underbrace{E(w_{red})}_{\approx 0.027})^2 * \frac{18}{37} \approx 1.0$$

The variance of $w_{14}$ is 
  $$var(w_{14}) = (-1-\underbrace{E(w_{14})}_{\approx 0.027})^2 * \frac{36}{37} + (35-\underbrace{E(w_{14})}_{\approx 0.027})^2 * \frac{1}{37} \approx 34.1$$

That is, a bet on 14 has the same expected payout as a bet on red, but
its payout is much more variable.
:::

The variance is the expected value (sum) of a square, which implies 
several standard properties:
  
1. It is always non-negative:
   $$var(x) \geq 0$$
2. For any constants $a$ and $b$:
   $$var(a + bx) = b^2 var(x)$$
3. The variance can be written as:
   $$var(x) = E(x^2) - E(x)^2$$

We can easily derive these properties but we will skip that now.

### Standard deviation {#standard-deviation}

The ***standard deviation*** of a random variable 
is defined as the (positive) square root of its variance.
$$\sigma_x = sd(x) = \sqrt{var(x)}$$

::: example
**Standard deviation in roulette**

The standard deviation of $r$ is:
  $$sd(r) = \sqrt{var(r)} \approx 0.5$$ 

The standard deviation of $w_{red}$ is:
  $$sd(w_{red}) = \sqrt{var(w_{red})} \approx 1.0$$ 
  
The standard deviation of $w_{14}$ is 
  $$sd(w_{14}) = \sqrt{var(w_{14})} \approx 5.8$$ 

:::

The standard deviation has analogous properties to the variance:

1. It is always non-negative:
   $$sd(x) \geq 0$$
2. For any constants $a$ and $b$:
   $$sd(a +bx) = b \, sd(x)$$

These properties follow directly from the corresponding properties of
the variance.

## Standard discrete distributions {#standard-distributions}

In principle, there are an infinite number of possible probability
distributions.  However, some probability distributions appear so 
often in applications that we have given them names. This provides 
a quick way to describe a particular distribution without 
writing out its PDF.  It also allows us to establish the properties
of a commonly-used distribution once, and use those results every
time we use that distribution.

### Bernoulli {#bernoulli}

The ***Bernoulli*** probability distribution is usually written:
$$x \sim Bernoulli(p)$$
It has discrete support $S_x = \{0,1\}$ and PDF:
$$f_x(a) = \begin{cases} (1-p) & a = 0 \\ p & a = 1 \\ 0 & a = \textrm{anything else}\\ \end{cases}$$
Note that the "Bernoulli distribution" isn't really a (single)
probability distribution.  Instead it is what
we call a ***parametric family*** of distributions.  That is,
the $Bernoulli(p)$ is a different distribution with a different PDF
for each value of the ***parameter*** $p$.

We typically use Bernoulli random variables to model the probability of some
random event $A$. If we define $x$ as the indicator variable $x=I(A)$, 
then $x \sim Bernoulli(p)$ where $p=\Pr(A)$.

::: example
**The Bernoulli distribution in roulette**

The variable $r = I(Red)$ has the $Bernoulli(18/37)$ distribution.
:::

The mean of a $Bernoulli(p)$ random variable is:
\begin{align}
  E(x) &= (1-p)*0 + p*1 \\
       &= p
\end{align}
and its variance is:
\begin{align}
var(x) &= E[(x-E(x))^2] \\
  &= E[(x-p)^2] \\
  &= (1-p)(0-p)^2 + p(1-p)^2 \\
  &= p(1-p)
\end{align}


### Binomial {#binomial}

The ***binomial*** probability distribution is usually written:
$$x \sim Binomial(n,p)$$
It has discrete support $S_x = \{0,1,2,\ldots,n\}$ and its PDF is:
$$f_x(a) = 
  \begin{cases} 
    \frac{n!}{a!(n-a)!} p^a(1-p)^{n-a} & a \in S_x \\ 
    0 & \textrm{anything else} \\ 
  \end{cases}$$
You do not need to memorize or even understand this formula.  The 
Excel function `BINOMDIST()` can be used to calculate the PDF or 
CDF of the binomial distribution, and the function `BINOM.INV()`
can be used to calculate its quantiles.

The binomial distribution is typically used to model frequencies or counts. We
can show that it is the distribution of how many of $n$ independent 
probability-$p$ events happen.  

For example, the basketball player Stephen Curry makes about
43\% of his 3-point shot attempts.  If each shot is independent of the others,
then the number of shots he makes in 10 attempts will have the
$Binomial(10,0.43)$ distribution.

::: example
**The binomial distribution in roulette**

Suppose we play 50 games of roulette, and bet on red in every game.
Let $WIN50$ be the number of times we win.  

Since the outcome of a single bet on red is $r \sim Bernoulli(18/37)$, 
this means that $WIN50 \sim Binomial(50,18/37)$.
:::

The mean and variance of a binomial random variable are:
  $$E(x) = np$$
  $$var(x) = np(1-p)$$


::: fyi
The formula for the binomial PDF looks strange, but it can actually
be derived from a fairly simple and common situation.  Let 
$(b_1,b_2,\ldots,b_n)$ be a sequence of $n$ independent random 
variables from the $Bernoulli(p)$ distribution and let:
  $$x = \sum_{i=1}^n b_i$$
count up the number of times that $b_i$ is equal to one (i.e., the event
modeled by $b_i$ happened).  Then it is possible to derive the
PDF for $y$, and that is the PDF we call $Binomial(n,p)$.  The derivation
is not easy, but the intuition is simple: 

- We can calculate the probability of the event $x=a$ by adding up 
  probability of its component outcomes.
- The number of outcomes in the event $x=a$ is $\frac{n!}{a!(n-a)!}$.
- The probability of each individual outcome in the event $x=a$ is 
  $p^a(1-p)^{n-a}$.

Therefore the probability of the event $x=a$ is   $\frac{n!}{a!(n-a)!}p^a(1-p)^{n-a}$.
:::  


### Discrete uniform {#discrete-uniform}

The ***discrete uniform*** distribution 
  $$x \sim DiscreteUniform(S_x)$$
is a distribution that puts equal probability on every value in 
a discrete set $S_x$. Its support is $S_x$ and its PDF is:
$$f_x(a) = \begin{cases}
          1/|S_x| & a \in S_x \\
          0 & a \notin S_x \\
          \end{cases}$$
Discrete uniform distributions appear in gambling and similar 
applications.  

::: example
**The discrete uniform distribution in roulette**

In our roulette example, the outcome $b$ has a discrete 
uniform distribution on $\Omega = \{0,1,\ldots,36\}$.
:::

## Chapter review {#review-random-variables}

To be added

### Practice problems {#problems-random-variables}

To be added.
