# Using R {#using-r}

```{r setup11, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      prompt = FALSE,
                      tidy = TRUE,
                      collapse = TRUE)
library("tidyverse")
```

Now that we have learned some basic R terminology and how to run R, our 
next step is to do something useful in R.  We will do this using the
Canadian employment data we have already worked with.  

::: goals
**Chapter goals**

In this chapter we will learn how to use R to:

- Read CSV files
- View data tables ("tibbles")
- Use filter, select, arrange, and mutate to transform data tables
- Calculate univariate statistics
- Produce simple but informative histograms and line graphs
:::

## Reading, viewing and cleaning data

Before doing any statistical or graphical analysis, we need to 
get the data into R.  We will also want to look at our data 
before diving into the analysis, and we may want to do some data
cleaning as well.

We will use numerous Tidyverse functions, so we need to load the 
Tidyverse package:
```{r LoadTidyverseAgain}
# Load the tidyverse
library("tidyverse")
```
We will also need to download our employment data set
from https://canvas.sfu.ca/files/15539454/.

### Reading a CSV file

Our first step will be reading the data in from the CSV file. The Tidyverse 
function to do this is called `read_csv()`.  It has one required argument: 
the name of the CSV file:
```{r ReadEmpDataFromCSV}
# The code below assumes that the file "EmploymentData.csv" is in 
# the working directory.  Change the argument below as needed to 
# make the function work in your environment 
EmpData <- read_csv("sampledata/EmploymentData.csv")
```
As you can see, R guesses each variable's data type, and reports its 
guess.  It is always a good idea to read this output and make sure
that everything is the way that we want it:

- The numeric variables are all stored as `col_double()`.  
  - This means double-precision (64 bit) real number
  - This is what we want.
- The two text variables are both stored as `col_character()`.  
  - This means character or text string
  - This is what we want.
- The *MonthYr* variable is also stored as `col_character()`.  
  - This is *not* what we want.  
  - We will want *MonthYr* to be stored explicitly as a date 
    variable, so we make a note of that issue here and will 
    fix it later.

We have assigned the data in the CSV file to the variable `EmpData`.

:::fyi
**Additional options**

Our data file happens to be a nice and tidy one, so `read_csv()` worked 
just fine with its default options.  Not all data files are so
tidy, so `read_csv()` has many optional arguments.  There are
also functions for other delimited file types:

- `read_csv2()` for files delimited by semicolons rather than commas
- `read_tsv()` for tab-delimited files
- `read_delim()` for files delimited using any other character

Base R function has a similar function called `read.csv()`, 
but `read_csv()` is preferable for various reasons.
:::

### Viewing a data table

The `read_csv()` function creates an object called a ***tibble***. A 
tibble is a Tidyverse object type that describes a tidy data table. 

- Each row in the tibble represents an observation
- Each column represents a variable, and has a name. 

The base R equivalent of a tibble is called a ***data frame***. Tibbles  
and data frames are interchangeable in most applications, but 
tibbles have some additional features that make them work better 
with the Tidyverse.

We have several ways of viewing the contents of a tibble. We can
start with the ***print*** function, which we have already seen in
other contexts:
```{r PrintEmpData}
print(EmpData)
```
Tibbles can be quite large, so the `print()` function will usually
show an abbreviated version of the table.

We can also see the whole table by executing the command `View(EmpData)` or
through RStudio:

1. Go to the **Environment** tab in the upper right window.
   - You will see a list of all variables currently in memory,
     including `EmpData`.
2. Double-click on `EmpData`.

You will see a spreadsheet-like display of `EmpData`. As in Excel, you can sort
and filter this table.  Unlike Excel, you cannot edit it here.

### Data table properties

There are several R functions available for exploring the properties 
of a data table.

We can obtain the column names of a tibble using the `names()` function:
```{r NamesEmpData}
names(EmpData)
```
and we can count the rows and columns with `nrow()` and `ncol()` respectively:
```{r NrowNcolEmpData}
nrow(EmpData)
ncol(EmpData)
```
We can access any variable by name using the `$` notation:
```{r LengthExample}
length(EmpData$UnempRate)
```
As you can see, the `length()` function returns the length of a vector.

### Modifying a data table

We will not spend a lot of time on data cleaning in R, as we can always clean
data in Excel and export it to R. However, we have a few Tidyverse tools
that are useful to learn.

The Tidyverse includes four core functions for modifying data: 

- `mutate()` allows us to add or change variables.
- `filter()` allows us to select particular observations, much
  like Excel's filter tool.
- `arrange()` allows us to sort observations, much like Excel's
  sort tool.
- `select()` allows us to select particular variables.

All four functions follow a common syntax that is designed to work with 
a convenient Tidyverse tool called the "pipe" operator.

#### The pipe operator

The ***pipe operator*** is part of the Tidyverse and is written `%>%`. Recall 
that an operator is just a symbol like "+" or "*" that performs some function
on whatever comes before it and whatever comes after it.

To see how it works, I'll show you a few examples:
```{r PipeExamples}
# This is equivalent to names(EmpData)
EmpData %>% names()
# This is equivalent to sqrt(2)
2 %>% sqrt()
# This is equivalent to cat(sqrt(2)," is the square root of 2")
2 %>% sqrt() %>% cat(" is the square root of 2")
```
As you can see, R's rule for interpreting the pipe operator is that the
object *before* the `%>%` is taken as the first argument for the function
*after* the `%>%`.  

The pipe operator does not add any functionality to R; anything you can do
with it can also be done without it.  But it addresses a common problem: we often 
want to perform multiple transformations on a data set, but doing so in 
the usual functional language can lead to code that is quite difficult to 
read.  The pipe operator can be used to create much more readable code, 
as we will see in the examples below.

#### Mutate

The most important data transformation function is ***mutate***, which 
allows us to change or add variables.  We will start by changing 
the *MonthYr* variable from character (text) to date, using the `as.Date()`
function: 
```{r MutateChangeMonthYr}
# Change MonthYr to date format
EmpData %>% 
  mutate(MonthYr = as.Date(MonthYr,"%m/%d/%Y"))
```
As you can see, the *MonthYr* column is now labeled as a date rather than text. Like
Excel, R has an internal representation of dates that allows for correct ordering
and calculations, but displays dates in a standard human-readable format.

Mutate can be used to add variables as well as changing them.  For example,
suppose we also want to create versions of *UnempRate* and *LFPRate* that
are expressed in percentages rather than decimal units:
```{r MutateAddUnempPct}
# Add UnempPct and LFPPct
EmpData %>% 
  mutate(UnempPct = 100*UnempRate) %>% 
  mutate(LFPPct = 100*LFPRate)
```
If you look closely, you can see that the *UnempPct* and *LFPPct* variables are
now included in the data table.

Before we go any further, note that we haven't yet changed the `EmpData` data 
table:
```{r PrintEmpDataAgain}
print(EmpData)
```
As you can see, the *MonthYr* variable is still listed as a character variable and
the new *UnempPct* and *LFPPct* variables do not seem to exist.

What has happened here?  Our original commands simply created a *new* object *based*
on `EmpData` that was then displayed on the screen.  In order to change `EmpData`
itself, we need to assign that new object *back* to `EmpData`:
```{r MutatePermanently}
# Make permanent changes to EmpData
EmpData <- EmpData %>%
  mutate(MonthYr = as.Date(MonthYr,"%m/%d/%Y")) %>% 
  mutate(UnempPct = 100*UnempRate) %>% 
  mutate(LFPPct = 100*LFPRate)
```
We can confirm that now we have changed `EmpData`:
```{r ConfirmPermanence}
print(EmpData)
```

#### Filter, arrange, and select

Now let's suppose we want to know more about the months in our data set 
with the *highest* unemployment rates. We can use `filter()` for
this purpose:
```{r FilterEmpData}
# This will give all of the observations with unemployment rates over 12.5%
EmpData %>% 
  filter(UnempPct > 12.5)
```
As you can see, only 8 of the 541 months in our data have unemployment rates
over 12.5% - the worst months of the 1982-83 recession, and April and May
of last year.

Now let's suppose that we only want to see a few pieces of information about those
months.  We can use `select()` to choose variables:
```{r SelectEmpData}
# This will take out all variables except a few
EmpData %>% 
  filter(UnempPct > 12.5) %>%
  select(MonthYr,UnempRate,LFPPct,PrimeMinister)
```
Finally, suppose that we want to show months in descending order by
unemployment rate (i.e., the highest unemployment rate first).  We 
can use `arrange()` to sort rows in this way:
```{r ArrangeEmpData}
# This will sort the rows by unemployment rate
EmpData %>% 
  filter(UnempPct > 12.5) %>%
  select(MonthYr,UnempPct,LFPPct,PrimeMinister) %>%
  arrange(UnempPct)
```
Hopefully you can see why the pipe operator is useful in making our code
clear and readable: 
```{r WithoutPipe}
# This is what the same code looks like without the pipe
arrange(select(filter(EmpData,UnempPct>12.5),MonthYr,UnempPct,LFPPct,PrimeMinister),UnempPct)
```
Now I should probably say: these results imply nothing meaningful about
the economic policy of either Pierre or Justin Trudeau.  The severe worldwide recessions in 1982-83 (caused by US monetary policy) and 2020-2021 (caused 
by the COVID-19 pandemic) were caused by world events largely outside the 
control of Canadian policy makers.

## Data analysis in R

Having read and cleaned our data set, we can now move on to some summary 
statistics.

### The summary function

The `summary()` function will give a basic summary of any object.  Exactly what
that summary looks like depends on the object.  For tibbles, `summary()` produces
a set of summary statistics for each variable:
```{r SummaryEmpData}
summary(EmpData)
```

### Univariate statistics 

The R function `mean()` calculates the sample average of any numeric 
vector:
```{r MeanUnempPct}
# Mean of a single variable
mean(EmpData$UnempPct)
```
There are many other functions in R to calculate other univariate summary
statistics:
```{r VarUnempPct}
# VAR calculates the sample variance
var(EmpData$UnempPct)
# SD calculates the standard deviation
sd(EmpData$UnempPct)
# MEDIAN calculates the sample median
median(EmpData$UnempPct)
```
As you can see, they work just like `mean()`.  

In real-world data, some variables have ***missing values*** for one or more
observations. For example, the *AnnPopGrowth* variable in our data set is
missing for the first year of data (1976), since calculating the growth rate
for 1976 would require data from 1975. In R, missing values are given the
special value `NA` which stands for "not available":
```{r ShowMissingValues}
EmpData %>%
  select(MonthYr,Population,AnnPopGrowth)
```
When we try to take the mean of this variable we also get `NA`:
```{r MeanAnnPopGrowth}
mean(EmpData$AnnPopGrowth)
```
This is because math in R follows the
[IEEE-754](https://en.wikipedia.org/wiki/IEEE_754) 
standard for numerical arithmetic, which says that any calculation
involving `NA` should also result in `NA`.  Whenever you have missing 
values, you should investigate before proceeding.  Sometimes (as in our case
here), missing values are for a good reason, other times they are the result
of a mistake or problem that needs to be fixed.

Once we have investigated the missing values, we can tell R explicitly
to exclude them from the calculation by adding the `na.rm = TRUE` option:
```{r MeanAnnPopGrowthWithoutNA}
mean(EmpData$AnnPopGrowth,na.rm=TRUE)
```

### Tables of statistics 

Suppose we want to calculate the sample average for each column in our
tibble. We could just call `mean()` for each of them, but there should
be a quicker way. Here is the code to do that:
```{r MeanTable}
# Mean of each column
EmpData %>%
  select(where(is.numeric)) %>%
  lapply(mean,na.rm=TRUE) 
```
I would not expect you to come up with this code, but maybe it
kind of makes sense.  

- The `select(where(is.numeric))` step selects only the columns in 
  `EmpData` that are numeric rather than text. 
- The `lapply(mean,na.rm=TRUE)` step calculates `mean(x,na.rm=TRUE)` 
  for each (numeric) column `x` in `EmpData`. 
  
We can use this method with any function that calculates a summary statistic:
```{r SDTable}
# Standard deviation of each column
EmpData %>%
  select(where(is.numeric)) %>%
  lapply(sd,na.rm=TRUE) 
```
  

### Frequency tables 

We can also construct frequency tables for both discrete and continuous
variables:
```{r CountTables}
# COUNT creates a frequency table for discrete variables
EmpData %>% 
  count(PrimeMinister)
# COUNT and CUT_INTERVAL create a binned frequency table
EmpData %>% 
  count(cut_interval(UnempPct,6))
```
As you might imagine, there are various ways of customizing the intervals
just like in Excel.

### Probability distributions in R

R has a family built-in functions for each commonly-used probability
distribution.  

For example:

- The  `dnorm()` function gives the normal PDF:
  ```{r}
  # The N(0,1) PDF, evaluated at 1.96
  dnorm(1.96)
  # The N(1,4) PDF, evaluated at 1.96
  dnorm(1.96,mean=1,sd=4)
  ```
- The `pnorm()` function gives the normal CDF:
  ```{r}
  # The N(0,1) CDF, evaluated at 1.96
  pnorm(1.97)
  ```
- The `qnorm()` function gives the inverse normal CDF (or quantile function):
  ```{r}
  # The 97.5 percentile of the N(0,1) CDF
  qnorm(0.975)
  ```
- The `rnorm()` function produces normal random numbers:
  ```{r}
  # Four random numbers from the N(0,1) distribution
  rnorm(4)
  ```

There is a similar set of functions available for the 
uniform distribution (`dunif`, `punif`, `qunif`, `runif`), the
binomial distribution (`dbinom`, `pbinom`, `qbinom`,`rbinom`),
and Student's T distribution (`dt`, `pt`, `qt`, `rt`), along 
with many others.

## Graphs with ggplot

The Tidyverse also contains a powerful graphics package called[^1101] ***ggplot***.

[^1101]: The package is technically called `ggplot2` since it is the second
       version of `ggplot`.  But everyone calls it "ggplot" anyway.

### Creating a graph

We can start by making a histogram of the unemployment rate:
```{r ggplotHistogram}
ggplot(data=EmpData,mapping=aes(x=UnempPct)) + 
  geom_histogram()
```
We can also make a time series (line) graph:
```{r ggplotTimeSeries}
ggplot(data=EmpData,mapping=aes(x=MonthYr,y=UnempPct)) + 
  geom_line() 
```

The `ggplot()` function has a non-standard syntax, so I'd like to go over 
it. 

- The first line sets up the basic characteristics of the graph:
    - The `data` argument tells R which data set (tibble) will be
      used
    - the `mapping` argument describes the basic ***aesthetics***
      of the graph, i.e., the relationship in the data we will
      be graphing.
      - For the histogram, our aesthetic includes only one variable
      - For the line graph, our aesthetic includes two variables
- The rest of the command is one or more statements separated by 
  a `+` sign.  These are called ***geometries*** and are geometric
  elements to be included in the plot.
    - The `geom_histogram()` geometry produces a histogram
    - The `geom_line()` geometry produces a line

A graph can include multiple geometries in a given graph, as we will see
shortly.

### Modifying a graph

As when making graphs in Excel, the basic graph gives us some useful information
but we can improve upon it in various ways.

#### Titles and labels

You can add a title and subtitle, and you can change the axis titles: 
```{r ggplotTitles}
ggplot(data=EmpData,aes(x=MonthYr,y=UnempPct)) + 
  geom_line() + 
  labs(title="Unemployment rate",
      subtitle="January 1976 - January 2021",
      caption="Source: Statistics Canada, Labour Force Survey",
      tag="Canada") +
  xlab("") +
  ylab("Unemployment rate, %")
```

#### Color 

Using color: you can change the color of any geometric element
using the `col=` argument:
```{r ggplotColor}
ggplot(data=EmpData,aes(x=MonthYr,y=UnempPct)) + 
  geom_line(col="blue") 
```
Colors can be given in ordinary English (or local language) words,
or with detailed color codes in RGB or CMYK format. 

Some geometric elements, such as the bars in a histogram, also have 
a ***fill*** color:
```{r ggplotFill}
ggplot(data=EmpData,aes(x=UnempPct)) + 
  geom_histogram(col="red",fill="blue") 
```
As you can see, the `col=` argument sets the color for the exterior
of each bar, and the `fill=` argument sets the color for the interior.

### Adding graph elements 

We can include multiple geometries in the same graph.  For example, we can
include lines for both unemployment and labour force participation:
```{r ggplotTwoLines}
ggplot(data=EmpData,aes(x=MonthYr,y=UnempPct)) + 
  geom_line(col="blue") +
  geom_line(aes(y=LFPPct),col="red")
```
A few things to note here:

- The third line gives `geom_line()` an aesthetics argument `aes(y=LFPPct)`.  This
  overrides the aesthetics in the first line.  
- We have used color to differentiate the two lines, but there is no legend 
  to tell the reader which line is which.  We will need to fix that.
- The vertical axis is labeled "UnempPct". We will need to fix that.

We could add a legend here, but it is better (and friendlier to the color-blind)
to just label the lines. We can use the `geom_text` geometry to do this:
```{r ggplotAddText}
ggplot(data=EmpData,aes(x=MonthYr)) + 
  geom_line(aes(y=UnempPct),col="blue") +
  geom_text(x=as.Date("1/1/2000","%m/%d/%Y"),y=15,label="Unemployment",col="blue") +
  geom_line(aes(y=LFPPct),col="red") +
  geom_text(x=as.Date("1/1/2000","%m/%d/%Y"),y=60,label="LFP",col="red")
```

The graphs below combine all of the features described above to yield clean
and clear graphs.

```{r ggplotFancyHistogram}
ggplot(data=EmpData,aes(x=UnempPct)) + 
  geom_histogram(binwidth=0.5,fill="blue") +
  geom_density() +
  labs(title="Unemployment rate",
      subtitle=paste("January 1976 - January 2021 (",
                     nrow(EmpData),
                     " months)",
                     sep="",
                     collapse=""),
      caption="Source: Statistics Canada, Labour Force Survey",
      tag="Canada") +
  xlab("Unemployment rate, %") +
  ylab("Count")
```

```{r ggplotFancyTimeSeries}
ggplot(data=EmpData,aes(x=MonthYr)) + 
  geom_line(aes(y=UnempPct),col="blue") +
  geom_text(x=as.Date("1/1/2000","%m/%d/%Y"),y=15,label="Unemployment",col="blue") +
  geom_line(aes(y=LFPPct),col="red") +
  geom_text(x=as.Date("1/1/2000","%m/%d/%Y"),y=60,label="LFP",col="red") +
  labs(title="Unemployment and LFP rates",
      subtitle=paste("January 1976 - January 2021 (",
                     nrow(EmpData),
                     " months)",
                     sep="",
                     collapse=""),
      caption="Source: Statistics Canada, Labour Force Survey",
      tag="Canada") +
  xlab("") +
  ylab("Percent")
```
