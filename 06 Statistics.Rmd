---
title: 'Chapter 6: Statistics'
author: "ECON 233, Brian Krauth"
date: "Spring 2021"
output: 
  html_document:
    theme: paper
    toc: true
    toc_float: true
    number_sections: true
  pdf_document:
    toc: yes
    number_sections: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Chapter overview

So far, we have learned how to model random events and random numbers, 
and we have learned how to calculate some commonly-used statistics from 
data.  This chapter ties all of that work together.

In this chapter we will:

- Use the theory of probability and random variables to model the random
  process generating our data set and the statistics we have calculated 
  from it.
- Apply and interpret the assumption of simple random sampling, and compare
  it to other sampling schemes.
- Calculate and interpret the mean and variance of a statistic from
  its sampling distribution.
- Calculate and interpret bias and mean squared error.
- Explain the law of large numbers, central limit theorem, and Slutsky's 
  theorem.


# Data and the data generating process

Suppose we have a data set. We would like to use that data set to learn
something about the mechanisms by which the data set was generated.
This process of learning from data is statistical analysis.

The basic idea of statistical analysis is that we will 

- Treat our data as the result of a random process called 
  the ***data generating process***
- Write down a model of the data generating process using the tools of
  probability. 
  - Our model of the DGP will typically include one or more unknown 
    features called *parameters*.
  - Both the data itself and any numbers (statistics) calculated from that 
    data can be considered random variables whose probability distribution
    could be derived from the DGP *if we knew the DGP*.
- Construct statistics to estimate the unknown parameters of the DGP.
  - We will want to use statistics that have a high probability of 
    prividing provide accurate estimates. 

## A general framework

Let $D$ be our data set.  We think of $D$ as a set of random variables 
with unknown joint distribution $P_D$.  This joint distribution
is called the ***data generating process*** for $D$. The exact DGP
is assumed to be unknown, but we usually have at least some information 
about it.

In this chapter we will assume that $D = (x_1,x_2,\ldots,x_n)$ 
is a data set with one variable and $n$ observations.  We 
use $x_i$ to refer to an arbitrary observation $i$.

We have some ***statistic*** $s =s(D)$, i.e., a number that is 
calculated from the data.

  - Since the data is observed/known, the value of the statistic
    is observed/known.
  - Since the elements of $D$ are random variables, $s$ is also 
    a random variable with a well-defined (but unknown) probability
    distribution that depends on the unknown DGP.

Often we are interested in some ***parameter*** $\theta = \theta(P_D)$ that 
describes some aspect of the DGP.  
  
  - Since the exact DGP is unknown, the exact value of $\theta$ is also
    unknown. 

We may use our statistic $s$ to tell us something about the value
of $\theta$:

  - Estimation: we may use $s$ as a best guess or ***estimate*** of 
    the true value of $\theta$.
  - Inference: we may use $s$ to infer whether a particular value
    of $\theta$ is plausible.

In this chapter we will focus on estimation.  We will cover statistical
inference in a later chapter.

## Sampling

### Random sampling from a population

In order to model the data generating process, we need to
model the entire joint distribution of $D$.  This
means:

- The probability distribution of each $x_i$
- The relationship between each of the $x_i$'s

Fortunately, we often can simplify this joint distribution
quite a bit by assuming that $D$ 
is ***independent and identically distributed*** (IID) 
or a ***simple random sample*** from a large ***population***.

A simple random sample has two features:

1. Independent: Each $x_i$ is independent of the others.
2. Identically distributed: Each $x_i$ comes from the same (unknown)
  probability distribution.

The reason we call this "independent and identically distributed"
is hopefully obvious, but what does it mean to say we have a 
"random sample" from a "population"? Well, one simple way of 
generating an IID sample is to:

1. Define the population of interest, for example all Canadian 
  residents.
2. Use some purely random mechanism to choose a small subset of cases
  from this population.
   - The subset is called our ***sample***
   - "Purely random" here means some mechanism like a coin flip
     or a computer's random number generator.
   - As a technical matter, the assumption of independence requires
      that we sample *with replacement*. This means we allow
      for the possibility that we sample the same case more than once.
      In practice this doesn't matter as long as the sample is small 
      relative to the population.
3. Collect data from every case in our sample.

It will turn out that a moderately-sized random sample provides 
surprisingly accurate information on the underlying population.

### Sample selection and representativeness

In the real world, a simple random is quite difficult to collect
from humans. Even if we are able to randomly select cases, we often
run into the following problems:

- ***Nonresponse*** occurs when a sampled individual does not provide
  the requested information:
  - ***Survey-level*** nonresponse occurs when the sampled individual does not
    answer any questions. This can occur if the sampled individual cannot
    be found, refuses to answer, or cannot answer (for example, is
    incapacitated due to illness or disability).
  - ***Item-level*** nonresponse occurs when the sampled individual does 
    not answer a particular question.  This can occur if the respondent
    refuses to answer, or the question is not applicable or has no
    valid answer.
- ***Censoring*** occurs when a particular quantity of interest cannot be
  observed for a particular case.  Censored outcomes are extremely common
  in economics, for example:
    - A classic example of censoring is the market wage for individuals 
      who are not currently employed. 
    - In supply/demand analysis, we only observe quantity supplied and
      quantity demanded at the current market price.
      
Each of these data problems affect whether our sample can be interpreted
as ***representing*** the population we care about. There are two basic
solutions to these problems:

- Imputation: we assume values for all missing quantities. For example,
  we might assume that the wage of each non-employed worker is equal
  to the average wage among employed workers with similar 
  characteristics.
- Redefine the population: redefine the population so that our data
  can be correctly interpreted as a random sample from that population.
  For example, instead of having a random sample of *Canadians*, we can
  interpret our data as a random sample of 
  *Canadians who would answer these questions if asked*. 
  
This is not an issue that has a purely technical solution, but requires
careful thought instead.  If we are imputing values, do we believe that
our imputation method is reasonable?  If we are redefining the population,
is that population one we care about?

### Alternatives to simple random sampling 

Not all useful data sets come from a simple random sample. For example:

- Some sample designs can be treated as if they were from a simple 
  random sample, or can be handled with minor modifications on
  the techniques used for simple random samples:
  - A ***stratified sample*** is gathered by dividing the population into
    strata based on some observable characteristics, and then randomly
    sampling a predetermined number of cases within each strata. 
      - Most professional surveys are constructed from stratified samples 
        rather than random samples.
      - Stratified sampling is often combined with *oversampling* of 
        some smaller strata. For example, the Labour Force Survey 
        oversamples residents of Prince Edward Island because a
        national random sample would not catch enough PEI residents to
        accurately measure PIE's unemployment rate.
  - A ***cluster sample*** is gathered by dividing the population
    into ***clusters***, randomly selecting some of these clusters, and
    sampling cases within the cluster.  
      - Educational data sets are often gathered this way: we pick a random 
        sample of schools, and then collect data from each student 
        within those schools.
  - A ***census*** gathers data on every case in the population. 
    - For example, we might have data on all 50 US states, or all 
      10 Canadian provinces, or all of the countries of the world. 
    - Data from administrative sources such as tax records or 
      school records often cover the entire population of interest as well. 
    - We typically interpret a census as a random sample from a hypothetical
      population of possible cases.
- Most macroeconomic data are ***time series***; that is they are observations
  of a particular quantity at regularly-spaced points in time.
  Time series have two features that are inconsistent with the random 
  sampling assumption:
    - They usually have clear time trends.  For example, Canada's real 
      GDP has been steadily growing for as long as we have observed it.
      This means that 2010 GDP is drawn from a distribution with a higher
      expected value than the distribution for 1910 GDP.
    - They usually exhibit what is called autocorrelation. Shocks to
      the economy that affect this year's GDP are likely to have 
      a similar (if smaller) effect on next year's GDP.  So the time periods
      close together are more closely related than time periods that 
      are far apart, even after we have accounted for the time trend.

  Time series data sometimes require more advanced techniques
  than we will learn in this class.
- A ***convenience sample*** is gathered by whatever method is convenient.
  - For example, we might gather a survey from people who walk by,
    or we might recruit our friends to participate in the survey.

  Convenience samples are the worst-case scenario; in many cases they
  simply aren't usable for accurate statistical analysis.
 
Many data sets combine several of these elements.  For example,
Canada's unemployment rate is calculated using data from the 
Labour Force Survey (LFS). The LFS is built from a stratified 
sample of the civilian non-institutionalized working-age population 
of Canada. There is also some clustering: the LFS will typically
interview whole households, and will do some geographic clustering
to save on travel costs. The LFS is gathered monthly, and the
resulting unemployment rate is a time series.


# Statistics and their properties

## Four examples

Let $s = s(D)$ be some statistic calculated from the data set $D$.
We will focus on four examples:

- The ***sample frequency*** or ***relative sample frequency***
  of the event $x_i \in A$ is defined as the proportion of cases
  in which the event occurs:
  $$\hat{f}_A = \frac{1}{n} \sum_{i=1}^n I(x \in A)$$
  A closely-related statistic is the ***absolute sample frequency***
  $n\hat{f}_A$ which is the *number* of cases in which the event 
  occurs.
- The ***sample average*** of $x_i$ is defined as: 
  $$\bar{x} = \frac{1}{n} \sum_{i=1}^n x_i$$
- The ***sample variance*** of $x_i$ is defined as: 
  $$s_x^2 = \frac{1}{n-1} \sum_{i=1}^n (x_i - \bar{x})^2$$
  A closely-related statistic is the ***sample standard deviation***
  $s_x = \sqrt{s_x^2}$ which is the square root of the sample variance.
- The ***sample median*** of $x_i$ is defined as:
  $$\hat{m}_x = m: \begin{cases} \hat{f}_{x < m} \leq 0.5 \\ \hat{f}_{x > m} \leq 0.5 \\ \end{cases}$$

## The sampling distribution

Since the data itself is a collection of random variables, any statistic
calculated from that data is also a random variable, with a probability
distribution that can be derived from the DGP.

This is easy to do for the sample frequency, so we will start there.  Let 
$y_i = I(x_i \in A)$ and let $p = \Pr(x_i \in A)$. This implies that:
  $$y_i \sim Bernoulli(p)$$
and
  $$n\hat{f}_A \sim Binomial(n,p)$$
In other words, we can calculate the exact probability distribution of
the sample frequency using the formula for the binomial distribution.

Unfortunately, calculating the exact probability distribution of 
most other statistics is more difficult.  We will return to that later,
but for now the important thing is just to remember that this probability
distribution $exists$.

## The mean and variance

If our statistic has a probability distribution, it (usually) has a mean
and variance as well. 

### The mean and variance of the sample frequency

Since the sample frequency has the binomial distribution, we have 
already seen its mean and variance:
  $$E(\hat{f}_A) = p$$
  $$var(\hat{f}_A) = \frac{p(1-p)}{n}$$
where $p = \Pr(x_i \in A)$.

### The mean and variance of the sample average

We can also calculate the mean and variance of the sample average.
Let $\mu_x = E(x_i)$ be the mean of $x_i$  Then the mean of $\bar{x}$ is:
$$E(\bar{x}) = E\left( \frac{1}{n} \sum_{i=1}^n x_i\right) = \frac{1}{n} \sum_{i=1}^n E\left( x_i\right) = \frac{1}{n} \sum_{i=1}^n \mu_x = \mu_x$$

Let $\sigma_x^2 = var(x_i)$ be the variance of $x_i$. Then the
variance of $\bar{x}$ is:
$$var(\bar{x}) = cov(\bar{x},\bar{x}) = E\left[\left( \frac{1}{n} \sum_{i=1}^n x_i-\mu\right)\left(\frac{1}{n} \sum_{i=1}^n x_i - \mu\right)\right] = \frac{1}{n^2} \sum_{i=1}^n\sum_{j=1}^n E\left((x_i-\mu)(x_j-\mu)\right) = \frac{1}{n^2} \sum_{i=1}^n\sum_{j=1}^n cov(x_i,x_j)$$
$$cov(x_i,x_j) = \begin{cases} \sigma_x^2 & i = j \\ 0 & i \neq j \\ \end{cases}$$ 
so:
$$var(\bar{x}) = \frac{1}{n^2} \sum_{i=1}^n \sigma_x^2 = \frac{n\sigma_x^2}{n^2} = \frac{\sigma_x^2}{n}$$

## Parameters and estimators

A ***parameter*** is an unknown number characterizing a DGP. For example,
if $x_i$ is a random sample from the $N(\mu,\sigma^2)$ distribution,
then both $\mu$ and $\sigma$ are parameters.

An ***estimator*** is a statistic that is being used to ***estimate***
(guess at the value of) an unknown parameter of interest.  The distinction
between estimator and estimate is a subtle one: we use "estimate" when
talking about our statistic as a number calculated for a specific data set
and "estimator" when talking about it as a random variable.

Let $s$ be a statistic we are using as an estimator of some parameter 
of interest $\theta$.  We can define its ***error*** as:
  $$err = s - \theta$$
In principle, we want $s$ to be a good estimator of $\theta$, i.e.,
we want $err$ to be as close to zero as possible.  There
are several major complications to keep in mind:

1. Always remember that $err$ is not an inherent property of the
  statistic - it is a property of the relationship between the statistic
  and the parameter of interest. A given statistic may be a good
  estimator of one parameter, and a bad estimator of another parameter.
2. Since $s$ is a random variable with a probability distribution, 
  so is $err$ is also a random variable with a proability distribution. 
3. Since the value of $\theta$ is unknown, the value of $err$ is also 
  unknown.

## Bias and mean squared error

In choosing an estimator, we can consider several criteria.

The first is the ***bias*** of the estimator, which is defined as:
$$bias(s) = E(s - \theta) = E(s) - \theta$$
The bias represents the average error we would expect over multiple
trials. 

Ideally we would want $bias(s)$ to be zero, in which case
we would say that $s$ is an ***unbiased*** estimator of $\theta$.
Note that bias is always defined relative to the parameter we wish 
to estimate, and is not an inherent property of the statistic.

For example, consider the sample average $\bar{x}$ in a random sample
as an estimator of the parameter $\mu_x = E(x_i)$. The bias is:
  $$bias(\bar{x}) = E(\bar{x}) - \mu_x = \mu_x - \mu_x = 0$$
That is, the sample average is an unbiased estimator of the population mean.
However, it is not the only unbiased estimator.  For example, suppose we 
simply take the value of $x_i$ in the first observation and throw
away the rest of the data.  This is also an unbiased estimator of $\mu_x$:
  $$bias(x_1) = E(x_1 - \mu_x) = \mu_x - \mu_x = 0$$
If there is one unbiased estimator, there are usually many. So we will
need another criterion to choose among unbiased estimators.

One option for the second criterion is the ***variance*** of the
estimator:
  $$var(s) = E[(s-(E(s))^2]$$
Low variance is better than high variance. 

Returning to our example, we have already found that the variance of 
the sample average is:
  $$var(\bar{x}) = \sigma^2/n$$
and the variance of the "first observation estimator: is:
  $$var(x_i) = \sigma^2$$
Since $\sigma^2/n < \sigma^2$, the sample average $\bar{x}$ has
lower variance than the first observation estimator $x_i$.
In fact, we can prove that $\bar{x}$ is the 
***minimum variance unbiased estimator*** of $\mu_x$, i.e.,
the unbiased estimator with the lowest variance.

Unfortunately, once we move beyond this simple case we run
into some complications:

- An unbiased estimator may not exist for a particular parameter, 
  in which case there is no minimum variance unbiased 
  estimator.
- There may be a slightly biased estimator that has much lower variance
  than any unbiased estimator. In fact, we can find examples
  in which the biased estimator *always$ has smaller error 
  than any unbiased estimator.

This suggests that we need a criterion that allows for a trade-off
between variance and bias.

The ***mean squared error*** of the estimator is defined as:
$$MSE(s) = E[(s-\theta)^2]$$
We can do a little math and show that:
$$MSE(s) = var(s) + [bias(s)]^2$$
The MSE criterion allows us to choose a biased estimator with low variance
over an unbiased estimator with high variance, and also allows us to choose
between biased estimators when no unbiased estimator exists.

Returning to our example, the mean squared error of the sample average is:
  $$MSE(\bar{x}) = var(\bar{x}) + [bias(\bar{x})]^2 = \frac{\sigma_x^2}{n} + 0^2 = \frac{\sigma_x^2}{n}$$
and the mean squared error of the first observation estimator is:
  $$MSE(x_1) = \sigma_x^2$$
Again the sample average is the preferred estimator.

The sample median is an example of a biased estimator for the population
median. To see this, consider a simple example in which
$x_i \sim Bernoulli(0.6)$ and $n = 1$.  Then the population median is:
  $$m_x = 1$$
and the sample median is:
  $$\hat{m}_x = x_1$$
The mean of $\hat{m}_x$ is:
  $$E(\hat{m}_x) = E(x_1) = p$$
and so the bias is 
  $$E(\hat{m}_x - m_x) = p - 1$$
Now this is a very simple example, but the basic idea applies more generally:
there is usually no unbiased estimator for the population median
or any other population quantile. (note exception for symmetric distributions)

Here's an example of a biased estimator that has lower MSE than any unbiased
estimator.  Suppose that $x_i \sim N(\mu_x,\sigma_x^2)$ where we already 
know that $\mu_x \geq 0$.  The sample average $\bar{x}$ will typically
be a pretty good estimator, but since we know $\mu_x \geq 0$ we can construct 
a better estimator. Let $s = max(\bar{x},0)$. This will be a better estimator
since it will be the same as $\bar{x}$ whenever $\bar{x} \geq 0$ and it
will be strictly closer than $\bar{x}$ to the true value $\mu_x$ whenever
$\bar{x} < 0$. With a little bit of math we can show that
this alternative estimator is biased:
$$E(s) > E(\bar{x}) = \mu_x$$
but has lower MSE than the (unbiased) sample average:
$$MSE(s) < MSE(\bar{x})$$

## Sample variances and standard errors

We can prove that the sample variance is an unbiased estimator
of the population variance:
  $$E(s_x^2) = \sigma_x^2 = var(x_i)$$
I'll leave this as an exercise. 

Recall that we found the variance of the sample $\bar{x}$ is:
  $$var(\bar{x}) = \frac{\sigma_x^2}{n} = \frac{var(x_i)}{n}$$
so $\frac{s_x^2}{n}$ is an unbiased estimator of $var(\bar{x})$:
  $$E\left(\frac{s_x^2}{n}\right) = \frac{E(s_x^2)}{n} = \frac{var(x_i)}{n} = var(\bar{x})$$
We can take the square root of this estimator to get the ***standard error***
of $\bar{x}$.  
  $$se(\bar{x}) = \frac{s_x}{\sqrt{n}}$$

In general, the standard error of a statistic is an estimator of the statistic's
standard deviation. It is not exactly unbiased, but is close and it has some other
useful properties that we will use later.

# Asymptotic analysis

## Small and large samples

So far, we have described statistics and estimators in terms
of their probability distribution and the mean, variance
and mean squared error associated with that probability 
distribution. 

We are able to do this fairly easy with both sample averages 
and sample frequencies (which are also sample averages)
because they are sums. Unfortunately, this is not so easy 
with other statistics (e.g. sample variances, medians, 
percentiles, etc.) that are nonlinear functions of the data.

In order to deal with those statistics, we need to construct
approximations based on the ***asymptotic*** properties
of the statistics.  Asymptotic properties are properties 
that hold approximately, with the approximation getting 
closer and closer to the truth as the sample size gets 
larger. 

Properties that hold exactly for any sample size 
(for example, the result we established earlier that
the sample average is an unbiased estimator for the mean)
are sometimes called ***exact*** or ***finite sample***
properties.

## The law of large numbers

The ***law of large numbers*** says that for a large enough random
sample, the sample average is very likely to be very close to the
corresponding population mean.  

To get an idea of how the law of large numbers works, let's take
a look at the mean squared error of the sample average in 
a random sample:
$$MSE(\bar{x}) = \frac{\sigma_x^2}{n}$$
Notice that as $n$ gets larger and larger, $MSE(\bar{x})$ gets smaller and 
smaller.  In the language of limits:
$$\lim_{n \rightarrow \infty} MSE(\bar{x}) = \lim_{n \rightarrow \infty} \frac{\sigma_x^2}{n} = 0$$


This takes us to the ***law of large numbers*** (LLN), which is one of the 
most important results in statistics.

**LAW OF LARGE NUMBERS**: Let $\bar{x}_n$ be the sample average 
from a random sample of size $n$ on the random variable $x_i$ with
mean $E(x_i) = \mu_x$ and let $\epsilon > 0$ be any strictly positive number.  Then:
$$\lim_{n \rightarrow \infty} \Pr( |\bar{x}_n -\mu| < \epsilon) = 1$$

What does this all mean?

- Define "very close" by choosing
  - some $\epsilon > 0$ telling me how close $\bar{x}$ needs
    to be to $\mu_x$.
  - some $\delta > 0$ telling me how close $\Pr(|\bar{x}-\mu_x| < \epsilon)$
    has to be to 1.
- The LLN tells me that I can find a sample size $n$ that is 
  "big enough" to guarantee that:
  $$\Pr(|\bar{x}-\mu_x| < \epsilon) > 1-\delta$$
Another way of saying this is that $\bar{x}_n$ ***converges in probability***
to $\mu_x$, or:
$$\bar{x}_n \rightarrow^p \mu_x$$

More generally, we say that the statistic $s$ is a ***consistent*** 
estimator of a parameter $\theta$ if:
$$s \rightarrow^P \theta$$
It will turn out that most of the statistics we use are consistent 
estimators of the thing we typically use them to estimate.

The law of large numbers is extremely powerful and important, as it
is the basis for both the casino industry, the insurance industry,
and much of the banking industry. 

A casino (or an insurance company, which is almost the same thing)
works by taking in a *large* number of *independent* small
bets. These bets have a small house advantage, so their expected 
benefit to the casino is positive. Any one bet can represent a 
sizeable loss to the casino, and if it is big enough can even 
result in the casino going bankrupt. But the LLN virtually
guarantees that the gains will outweigh the losses as long as the
casino takes in a large enough number of independent bets.

Now we could probably do without casinos, but insurance is another 
matter. The way the insurance industry works is that each of
us faces a small risk of a catastrophic cost: a house that
burns down, a car accident leading to serious injury, etc.
Insurance works by collecting a little bit of money from each
of us, and paying out a lot of money to the small number of 
people who have claims.  As with a casino, their expected
payout is less than their expected revenue, and so their
expected profits are positive.  On its own, that doesn't
mean their actual profits will be positive: positive expected
profits can still mean a high probability of big losses.
But if the insurance company covers a large number of 
*independent* risks, the law of large numbers guarantees
that the insurer will (almost) always make positive profits.

Sometimes insurance companies do lose money, and even go 
bankrupt. The usual cause of this is a big systemic 
event like a natural disaster, pandemic or financial crisis
that affects everyone.  Here the independence needed for the LLN
does not apply.

## The central limit theorem

The Central Limit Theorem is an even more powerful result in statistics.


**CENTRAL LIMIT THEOREM**: Let $\bar{x}_n$ be the sample average 
from a random sample of size $n$ on the random variable $x_i$ with
mean $E(x_i) = \mu_x$ and variance $var(x_i) = \sigma_x^2$. Let
  $$z_n = \sqrt{n} \frac{\bar{x}_n - \mu_x}{\sigma_x}$$
and let $F_n$ be the CDF of $z_n$.  Then for every $a \in \mathbb{R}$:
  $$\lim_{n \rightarrow \infty} |F_n(a) - \Phi(a)| = 0$$
where $\Phi(\cdot)$ is the CDF of the $N(0,1)$ distribution.

Another way of saying this is that $z_n$ ***converges in distribution***
to a $N(0,1) random variable, or:
  $$z_n \rightarrow^D N(0,1)$$

What does the central limit theorem mean?

  - Fundamentally, it means that if $n$ is big enough then the probability
    distribution of $\bar{x}_n$ is approximately normal 
    *no matter what the original distribution of $x_i$ looks like.*
  - In order for the CLT to apply, we need to rescale $\bar{x}_n$
    so that it has zero mean (by subtracting $E(\bar{x}_n) = \mu_x$) 
    and constant variance as $n$ increases (by dividing by 
    $sd(\bar{x}_n) = \sigma_x/\sqrt{n}$)).  That rescaled sample
    average is $z_n$.  
  - In practice, we don't usually know $\mu_x$ or $\sigma_x$ so 
    we can't calculate $z_n$ from data. Fortunately, there are some
    tricks for getting around this problem that we will talk
    about later.
    
## Slutsky's theorem

Our final tool is a result called **Slutsky's theorem**

**SLUTSKY THEOREM**: Let $g(\cdot)$ be a continuous function. Then:
  $$w_n \rightarrow^p w \implies g(w_n) \rightarrow^p g(w)$$
and:
  $$w_n \rightarrow^D w \implies g(w_n) \rightarrow^D g(w)$$

What is the importance of Slutsky's theorem?

  - It extends the law of large numbers to any continuous function
    of a sample average. This is important because:
    - Most commonly-used statistics can be written as a continuous
      function of sample averages, so the LLN applies to them
    - As a result of this, most commonly used statistics 
      (e.g., the sample median) can be shown to be consistent
      estimators of the population parameters they are typically
      used to estmate.
  - It extends the central limit theorem to any continuous function
    of the transformed sample average $z_n$. This will turn
    out to be very important when we get to hypothesis testing.
