# Probability and random events {#probability-and-random-events}

***Probability*** is a mathematical system for modeling a random process
so that we can understand it and/or make predictions about its future 
results. Probability is an essential tool for casinos, as well as for
banks, insurance companies, and any other organization that manages risks.
It also provides the mathematical framework for statistical analysis.

::: {.goals data-latex=""}
**Chapter goals**

In this chapter, we will learn how to:

1.  Define the outcome and sample space for a given random process
2.  Use set theory to define and manipulate events for a given random process.
3.  Calculate event probabilities from elementary event probabilities.
4.  Calculate and interpret joint and conditional probabilities
5.  Apply the axioms and derived rules of probability.
6.  Interpret and evaluate the claim that two events are independent.
7.  Use the law of total probability and Bayes' law
:::

To prepare for this chapter, please review the sections on [Sets](#sets) and
[Functions](#sets) in the [Math Review](#math-review) appendix.

## Randomness and uncertainty

Economics studies choice behavior and its consequences, and nearly every choice
we make is affected by ***randomness*** and ***uncertainty***. That is, we often
cannot predict future conditions with certainty, and we do not even have full
information on current conditions.

As in other areas of economics, we can better understand random and uncertain
events by building a model. The first step in building a model is to describe
the situation of interest.

::: example
**Example application: Roulette**

We will develop ideas by considering the casino game of **Roulette**.
The picture below shows what a roulette wheel looks like.

![roulette wheel image](bin/roulette.png)
Source: <a href="https://www.vecteezy.com/free-vector/roulette">Roulette Vectors by Vecteezy</a>

Here are the rules:

- It features 
  - a ball.
  - a spinning wheel with numbered/colored slots. 
  - a table with a grid of numbers on which to place bets
- The slots are numbered from 0 to 36
  - Slot number 0 is green
  - 18 slots are red
  - 18 slots are black.
  - The picture above depicts an American roulette table, which has an 
    additional green slot labeled "00",
  - I will assume we have a European roulette table, which does not include
    the "00" slot.
- Players can place various bets on the table including:
  - Red (ball lands on any red number) pays \$1 per \$1 bet
  - Black (ball lands on any black number) pays \$1 per \$1 bet
  - A straight bet on any specific number (ball lands on that number)
    pays \$35 per \$1 bet

Like other casino games, a roulette game is an example of a random process:
something will happen, someone (the players and the casino) cares what
will happen, but no one knows in advance what will happen.
:::

## Outcomes and events {#outcomes-and-events}

To build a probabilistic model of a random process, we start by defining
the ***outcome*** we are interested in.  An outcome can be a simple yes/no
result, it can be a number, or it can be a much more complex object. The
outcome should be a complete description of the random process, in the
sense that everything we are interested in can be defined in terms of
the outcome.

::: example
**Outcomes in roulette**

The outcome of a single game of roulette can be defined as the number of 
the slot in which the ball lands.  Call that number $b$.
:::

The set of all possible outcomes is called the ***sample space***.

::: example
**The sample space in roulette**

The sample space for a game of roulette can be defined as
the set of all numbers the ball can land on:
   $$\Omega = \{0,1,2,\ldots,36\}$$
This sample space has $|\Omega| = 37$ elements.
:::

Next, we define a set of ***events*** that we are interested in.
We can think of an event as either:

 - A statement that is either true or false depending on the outcome OR
 - A subset of the sample space 

These two concepts are equivalent, though the subset concept 
makes the math clearer.
 
An event that contains only one outcome is called an ***elementary event***.
I will mostly treat "elementary event" and "outcome" interchangeably, but
there is a minor technical distinction: the outcome $14$ is a number, while the
elementary event $\{14\}$ is a set.

::: example
**Events in roulette**

These roulette events are well-defined for our sample space: 

- Ball lands on 14:
  $$b \in \{14\}$$
- Ball lands on red:
  \begin{align}
    b \in Red &= \left\{\begin{aligned}
      & 1,3,5,7,9,12,14,16,18, \\
      & 19,21,23,25,27,30,32,34,36 \\
      \end{aligned}\right\}
  \end{align}
- Ball lands on black:
  \begin{align}
    b \in Black &= \left\{\begin{aligned}
      & 2,4,6,8,10,11,13,15,17, \\
      & 20,22,24,26,28,29,31,33,35 \\
      \end{aligned}\right\}
  \end{align}
- Ball lands on one of the first 12 numbers:
   $$b \in First12 = \{1,2,3,4,5,6,7,8,9,10,11,12\}$$

You can see many other bets on the table such as "Even", "Odd",
"1 to 18" and so on.  We can define an event for each of these bets, or for
any other combination of values for $b$.
:::

Since events are sets, we can work with events using the terminology and
mathematical tools for sets.

::: example
**Relationships among events**

In our roulette example:

- Two events are *identical* $(A = B)$ if they contain exactly the same outcomes:
  - The event "ball lands on 14" and "a bet on 14 wins"
    are identical since $\{14\} = \{14\}$.
  - Intuitively, identical means they are just two different ways of describing
    the same event.
- An event *implies* another event $(A \subset B)$ if all of its outcomes are also in 
  the implied event 
  - The event "ball lands on 14"  implies the event "ball lands on red" 
    since $\{14\} \subset Red$.
  - When an event happens, any event it implies also happens.
- Two events are *disjoint* $(A \cap B) = \emptyset$
  if they share no outcomes:
  - The events "ball lands on red" and "ball lands on black" are disjoint 
    since $Red \cap Black = \emptyset$.
  - Two disjoint events cannot both happen because there is no possible outcome
    that makes them both true.
  - But two disjoint events can both fail to happen. For example, if the ball
    lands in the green zero slot ($b = 0$), neither red nor black wins.
- Any two elementary events are either identical or disjoint
   - The events "ball lands on 14" and "ball lands on 25" are disjoint
     since $\{14\} \cap \{25\} = \emptyset$.
:::

## Probabilities {#probabilities}

Our final step is to define a ***probability distribution***
for this random process, which is a function that assigns
a number to each possible event.  The number is called 
the event's ***probability***. 

Probabilities are normally between zero and one:

- If an event has probability one, it definitely *will* happen.
- If an event has probability zero, it definitely *will not* happen
- If an event has probability strictly between zero and one, it *might* happen.
- An event with a higher probability is more likely to happen.

Where does this probability distribution come from? That's a good question,
but we will take it as given for the moment.

### The axioms of probability {#the-axioms-of-probability}

All valid probability distributions must obey the following three conditions, which are sometimes called the ***axioms*** of probability.

1. Probabilities are never negative:
   $$\Pr(A) \geq 0$$
2. One of the outcomes in the sample space will definitely happen:
   $$\Pr(\Omega) = 1$$
3. For any two *disjoint* events $A$ and $B$, the probability that
   $A$ or $B$ happen is the sum of their individual probabilities:
   $$\Pr(A \cup B) = \Pr(A) + \Pr(B)$$

The first two axioms are relatively straightforward, but the third may need
some explanation. Remember that two events are disjoint if they have no
outcomes in common, i.e., it is not possible for both events to happen. For
example, the event "the unemployment rate is 5\%" and the event
"the unemployment rate is 3\%" are disjoint.  Axiom three means that we can
calculate the probability the unemployment rate is 3\% or 5\% by adding the
probability of 3\% and the probability of 5\%.


### Additional rules for probabilities {#some-rules-for-probabilities}

Probability distributions have many other properties, but they
can all be derived from the three axioms.

Let $A$ and $B$ be two (not necessarily disjoint) events.  Then our three axioms
of probability imply several additional rules:

- Probabilities cannot be higher than one.
   $$\Pr(A) \leq 1$$
- Probabilities of identical events are identical:
   $$A = B \implies \Pr(A) = \Pr(B)$$
- Probabilities of implied events are larger:
   $$A \subset B \implies \Pr(A) \leq \Pr(B)$$
- The probability of an event *not* happening is:
   $$\Pr(A^C) = 1 - \Pr(A)$$
- The probability of nothing happening is:
   $$\Pr(\emptyset) = 0$$
- The probability of either $A$ or $B$ happening is:
  \begin{align}
    \Pr(A \cup B) &= \Pr(A) + \Pr(B) - \Pr(A \cap B) \\
      &\leq \Pr(A) +\Pr(B)
  \end{align}

These results are not hard to prove, but I will not go through the proofs.
However, I will use these results so you should be familiar with them.

### Calculating probabilities

To calculate probabilities we will need to use information or assumptions
about the random process, and can then apply the axioms of probability and the
associated rules.

Since this is an introductory course, our sample space will usually
contain a finite number of outcomes, as in our roulette example.  In
that case, probability calculations can be made in two simple steps:

1. Find the probability of each elementary event.
2. To find the probability of a specific event, just add up the probabilities
   of its elementary events.

Finding the probability of each elementary event usually requires us to
understand something about the random process itself.

::: example
**Outcome probabilities for a fair roulette game**

Casinos are required by law to operate "fair" games, and are subject to heavy
penalties if they operate unfair ones.  In the context of roulette, a fair game
is one in which each number has the same probability.

Let's assume that the roulette wheel is "fair" in the sense that each 
outcome has the same probability. Note that this is just an assumption, and
it may not actually be true. Later on, we will use data
and statistics to evaluate whether a roulette wheel is *actually* fair.

Asssuming each outcome has the same probability, let that probability be:
   $$p = \Pr(b = 0) = \Pr(b = 1) = \cdots = \Pr(b = 36)$$
To find the correct value of $p$ we use the axioms of probability:

- By axiom #2, one of the outcomes will happen:
   $$\Pr(\Omega) = 1$$
- Since the different outcomes are disjoint, axiom #3 implies that:
   $$\underbrace{\Pr(\Omega))}_{1} = \underbrace{\Pr(\{0\})}_{p} + \underbrace{\Pr(\{1\})}_{p} + \cdots + \underbrace{\Pr(\{36\})}_{p}$$
- Since there are 37 possible outcomes, we can rewrite this equation as:
   $$1 = 37p$$
- We can then solve for $p$ to get:
   $$p = 1/37 \approx 0.027$$
That is, each of the 37 elementary events have a probability of $1/37$
or about 2.7\%.
:::

Once we have the probabilities of each elementary event, calculating any
other probability is just a matter of adding up.

::: example
**Event probabilities for a fair roulette game**

In the roulette example, the probability of any event $A$ is just the number
of outcomes in $A$ times the probability of each outcome $1/37$:
   $$ \Pr(A) = |A|*1/37$$
The notation $|A|$ just means the size of (number of elements in) the set $A$.

For example:
$$\Pr(b=25) = |\{25\}|*1/37 = 1/37 \approx 0.027$$
$$\Pr(Red) = |Red|*1/37 = 18/37 \approx 0.486$$
$$\Pr(Even) = |Even|*1/37 = 18/37 \approx 0.486$$
$$\Pr(First12) = |First12|*1/37 = 12/37 \approx 0.324$$
:::

However, not all sample spaces contain a finite number of outcomes.  For
example, suppose we are interested in using probability to model the
unemployment rate, or a person's income.  Those are real numbers, and can 
take on any of an infinite number of values.  This adds a few complications,
and is the reason that the probability axioms refer to events (sets of
outcomes) and not individual outcomes.

::: {.fyi data-latex=""}
**What do probabilities really mean?**

What does it really mean to say that the probability of the ball landing in 
a red slot is about 0.486? That's actually a tough question. There
are two standard interpretations for probabilities:

- *Frequentist or classical interpretation*: we are thinking of 
  the random process as something that could be repeated many times,
  and the probability of an event is the approximate fraction of times
  that the event will occur.  That is, if you go to a casino and
  bet 1000 times on Red, you will win about 486 times. 
- *Bayesian or subjectivist interpretation*: the random process
  is a one-time occurrence, but we have limited information about
  it and the probability of event represents the strength of 
  our belief that the event will happen.

The frequentist interpretation of probability is well-suited
for simple repeated settings like casino games or car insurance,
while the Bayesian interpretation makes more sense for predicting
one-time events like the results of a particular election.
:::

## Joint and conditional probabilities {#related-events}

We are often interested in more than one event, and want to talk about how 
they are related. For example:

 - In some casino games like poker or blackjack, players take an additional 
   action after partial information about the outcome is revealed.
 - Political scientists often use polls to predict the winner of an election.
 - Finance people often want to model multiple market scenarios and 
   forecast a company's earnings under each of them.
 - Economists often have data on current economic conditions and want 
   to predict future economic conditions.
 - Doctors often want to know the probability that a particular treatment will
   be effective based on test results and patient characteristics.

This section will develop some tools for dealing with the relationship
between different random events.

### Joint probabilities {#joint-probabilities}

The ***joint probability*** of two events $A$ *and* $B$ is the probability that
they *both* happen:
  $$\Pr(A \cap B)$$
Remember that the intersection ($\cap$) of $A$ and $B$ is the set of all 
outcomes that are in both $A$ and $B$.

We can calculate joint probabilities by constructing a new event from the
intersection of the two original events, and then calculating the probability of
that new event.

::: example
**Joint probabilities for roulette bets**

Suppose that Al has bet on Red, and Betty has bet on Even. They agree to go out
to a fancy dinner tonight if they both win.  How likely is this to happen?

The events "Red wins" and "Even wins" can be defined:
  \begin{align}
    Red &= \left\{\begin{aligned}
      & 1,3,5,7,9,12,14,16,18, \\
      & 19,21,23,25,27,30,32,34,36 \\
      \end{aligned}\right\} \\
    Even &= \left\{\begin{aligned}
      & 2,4,6,8,10,12,14,16,18, \\
      & 20,22,24,26,28,30,32,34,36 \\
      \end{aligned}\right\}
  \end{align}
Note that zero doesn't count as an even number in roulette (if it did, the
player would have an advantage over the house).

This event "Red and Even both win" is just the intersection of $Red$ and $Even$
so this joint probability is:
  \begin{align}
    \Pr(Red \cap Even) &= \Pr(\{12,14,16,18,30,32,34,36\}) \\
      &= 8/37 \\
      &\approx 0.216
  \end{align}
So there is a 21.6\% chance of a fancy dinner.
:::

Joint probabilities are just probabilities, so they obey all of the axioms
and rules of probability described in Section \@ref(probabilities).

### Conditional probabilities {#conditional-probabilities}

The ***conditional probability*** of an event $A$ ***given*** another
event $B$ is defined as:
   $$\Pr(A|B) = \frac{\Pr(A \cap B)}{\Pr(B)}$$
The conditional probability answers the question: if we already know that 
$B$ is true, what are the chances that $A$ is true?

To calculate a conditional probability, just calculate the two components
and apply the formula above.

::: example
**Conditional probabilities in roulette**

Suppose that Betty has bet on even, and she excitedly yells out
"I won! Woo hoo!"  Al bet on Red, and Carl bet on 14. Knowing that Betty
has won, what are the chances Al and Carl also won?

This question can be answered using the conditional probabilities:
   $$\Pr(Red|Even) = \frac{\Pr(Red \cap Even)}{\Pr(Even)} = \frac{8/37}{18/37} \approx 0.444$$
   $$\Pr(b = 14|Even) = \frac{\Pr(b = 14 \cap Even)}{\Pr(Even)} = \frac{1/37}{18/37} \approx 0.056$$
That is, Betty winning is associated with a reduced probability of Al winning
(since $0.444 < 0.486$) and an increased probability of Carl winning (since
$0.056 > 0.027$).
:::

Conditional probabilities are not particularly useful in roulette, which is a
simple "one shot" game.  But they are very important when playing multi-step
games like poker or blackjack. At the beginning of a hand of poker, every player
has equal chance of having a winning hand. But that is no longer true after the
players see their cards - having "good" cards increases your chance of winning,
and having "bad" cards decreases that chance. Players get to make bets after
seeing their cards, so your bet should be based on $\Pr(win|YourCards)$ rather
than $\Pr(win)$. Good poker players have detailed (but sometimes informal)
knowledge of these conditional probabilities.

Like joint probabilities, conditional probabilities are just probabilities,
so they obey all of the axioms and rules of probability described in 
Section \@ref(probabilities).

### Independent events {#independent-events}

One common "trick" in modeling joint and conditional probabilities is to assume
that certain events are unrelated to each other. This can simplify the math
significantly.

We say that two events $A$ and $B$ are ***independent*** if their joint
probability is just the two individual probabilities multiplied together:
  $$\Pr(A \cap B) = \Pr(A)\Pr(B)$$
We sometimes express independence using the notation $A \bot B$.

The definition of independence is not very intuitive, but we can clarify
it by doing a little math.  Consider two independent events $A$
and $B$ that have nonzero[^301] probability.  Then by the definition of
independence:
  $$\Pr(A|B) = \frac{\Pr(A \cap B)}{\Pr(B)} = \frac{\Pr(A)\Pr(B)}{\Pr(B)} = \Pr(A)$$
By the same reasoning:
  $$\Pr(B|A) = \Pr(B)$$
In other words, knowing that one of these events are true 
tells you nothing useful about whether the other the other event
is true.

[^301]: You may wonder: if it makes more sense to describe independence 
      in terms of conditional probabilities, why do we define it in 
      terms of joint probabilities?  The key is the requirement that
      the events have nonzero probability. When $B$ has zero
      probability the conditional probability $\Pr(A|B)$ is not
      well defined since its denominator is zero.

When would it be reasonable to assume two events are independent?
The typical scenario would be where there is simply no 
physical or logical relationship between them, usually due
to a separation in time and space.

::: example
**Independence across roulette games**

We will show below that events related to a *single* roulette game
are not necessarily independent.  But the outcomes/events of 
*two different* roulette games can be reasonably assumed to be independent
of one another.  We can use that independence assumption in the following
calculation.

Suppose that I bring \$100 to a casino this afternoon for a few games 
of roulette. I bet all of my money on Red for the first game.

- If I lose, I am broke and stop playing.
- If I win, I keep all of my money (both my initial bet and my winnings)
  on Red for the next spin.  
- I keep playing until I run out of money.

After 3 games:

 - If Red wins all 3 games, I have $w = \$800$.
 - Otherwise, I have nothing $w = \$0$

What is the probability of each of these events?  Since we can 
assume that each game's outcome is independent, this is an easy
problem:
  \begin{align}
    \Pr(w = \$800) &= \Pr(Red_1 \cap Red_2 \cap Red_3) \\
      &= \Pr(Red_1) \times \Pr(Red_2) \times \Pr(Red_3) (\#eq:indep) \\
      &= (18/37) \times (18/37) \times (18/37) \approx 0.115 \\
    \Pr(w = \$0) &= 1 - \Pr(w = \$800) \\
      &\approx 0.885 \\
  \end{align}
So we have an 11.5\% chance of winning big, and an 88.5\% chance
of going broke.

Very important: equation \@ref(eq:indep) only follows from the previous
equation because we have assumed the events $Red_1$, $Red_2$, and $Red_3$
are independent.
:::

When is it *not* reasonable to assume that events are independent? In
almost any other case.  Remember that different events are defined in terms of
the same underlying outcome, so they are typically related unless 
you have some very specific reason to assume otherwise.

::: example
**Independence within a roulette game?**

Consider the events "Red wins" and "Even wins" within a single roulette game.
We earlier showed that the unconditional probability that Red wins is:
  $$\Pr(Red) = 18/37 \approx 0.486$$
and that the conditional probability that Red wins given that Even wins is:
   $$\Pr(Red|Even) = 8/18 \approx 0.444$$
Since $0.44 \neq 0.486$, these two events are *not* independent.
:::

A common mistake by students who are new to probability and
statistics is to take results that *only* apply under independence
and use them when there is no reason to believe that independence
holds.  Don't make this mistake: independence is an assumption, 
and one that can easily be incorrect.

### Law of total probability

In addition to the results we have already discussed, there are two
important results using conditional probabilities.
The first is the ***law of total probability***, which
is a rule for determining unconditional probabilities 
from conditional probabilities:

  $$\Pr(A) = \Pr(A|B)\Pr(B) + \Pr(A|B^c)\Pr(B^c)$$

The law of total probability allows us to create a set of scenarios,
calculate probabilities under each scenario, and then add them up. It 
is useful when we are modeling random outcomes that occur in multiple
stages, for example a poker game or an energy company making a series of
investments to develop an oil field.

::: example
**The law of total probability in poker**

Suppose you are playing [Texas hold'em poker](https://en.wikipedia.org/wiki/Texas_hold_'em)
with a few friends, and the hand has one card left to deal (the "river"). If
the last card has a heart on it (25\% probability) you will have a flush and
win the hand with a probability you estimate to be 90\%.  If not, you will 
not have a flush, but still have a win probability you estimate to be 10\%.
Given this information, what are your overall chances of winning?

The answer can be calculated using the law of total probability:
  \begin{align}
    \Pr(Win) &= \Pr(\textrm{Win}|\textrm{Hearts})\Pr(\textrm{Hearts}) 
              + \Pr(\textrm{Win}|\textrm{not Hearts})\Pr(\textrm{not Hearts}) \\
      &= 0.9*0.25 + 0.1*0.75 \\
      &= 0.3
  \end{align}
So you have a 30\% chance of winning. 
:::

### Bayes' law

The second is ***Bayes' law***, which is a rule for determining 
conditional probabilities:
  $$\Pr(A|B) = \frac{\Pr(B|A)\Pr(A)}{\Pr(B)}$$
Bayes' law is particularly useful in evaluating evidence, because
it allows us to restate one conditional probability in terms of
another. That is, we are interested in whether a statement $A$ is true or
false given our observation $B$, and Bayes' law allows us to state this
conditional probability in terms of the probability of observing $B$ when
$A$ is true.

::: example
**False positives in medical testing**

When someone is tested for a disease, the test comes back either
"positive" (the person has the disease) or "negative" (the person does
not have the disease). However, no test is perfect. Sometimes people
who do not have the disease test positive ("false positives") and 
sometimes people who do have the disease test negative 
("false negative").

Let the event $T$ mean a particular patient tests positive
for a disease, and let the event $D$ mean that this patient 
actually has the disease. 

The *sensitivity* of the test is a sick patient's probability
of testing positive:
   $$\Pr(T|D) = p$$
the *specificity* of the test is a healthy patient's probability
of testing negative:
   $$\Pr(T^c|D^c) = q$$
and the *prevalence* of the infection is the probability that
a given patient has the disease:
   $$\Pr(D) = d$$
Suppose that a patient has tested positive.  What is the
probability that he has the disease, i.e. what the value of
$\Pr(D|T)$?

This is a classic probability question, as it makes use
of Bayes' law and the law of total probability, and it has
obvious practical importance.

Since we want a conditional probability, we start by stating Bayes' law:
   $$\Pr(D|T) = = \frac{\Pr(T|D)\Pr(D)}{\Pr(T)}$$
Bayes' law will allow us to calculate $\Pr(D|T)$ if we can find 
the components of the right side of this equation. 
We already know that $\Pr(T|D)=p$ and $\Pr(D)=d$, so all we need
is to find $\Pr(T)$.

Since $\Pr(T)$ is an unconditional probability, we can use
the law of total probability:
   $$\Pr(T) = \underbrace{\Pr(T|D)}_{p}
              \underbrace{\Pr(D)}_{d} 
            + \underbrace{\Pr(T|D^c)}_{1-q}
              \underbrace{\Pr(D^c)}_{1-d}$$
Plugging these results into our formula we get:
   $$\Pr(D|T) = = \frac{pd}{pd + (1-q)(1-d)}$$
which is the result we need.

Now, let's try out some numbers.  Suppose that false positives are rare 
($q = 0.99$), and false negatives never happen ($p=1$).

- Suppose the disease itself is fairly common ($d = 0.10$).  Then a patient
  who tests positive is likely to have the disease:
   $$\Pr(D|T) = = \frac{1*0.1}{1*0.1 + (1-0.99)*(1-0.1)} \approx 0.917$$
- Suppose the disease itself is quite rare ($d = 0.001$).  Then even a patient
  who tests positive is unlikely to have the disease:
   $$\Pr(D|T) = = \frac{1*0.001}{1*0.001 + (1-0.99)*(1-0.001)} \approx 0.091$$

In other words, the exact same test has a very different meaning depending
on the prevalence in the population: when the disease is common a positive
test means a 91.7% chance of having the disease, and when the disease
is rare a positive test result means a 9.1% chance of having the disease.

This general issue (even a small false positive rate can have a big impact
when prevalence is low) appeared repeatedly in March and April of 2020. Several 
studies by well-known researchers[^302] dramatically overestimated the early
prevalence of the COVID-19 virus and thus dramatically underestimated its
fatality rate. These studies were regularly cited as support by those who 
wanted to substantially relax public health restrictions in April 2020,
and had substantial real world consequences.
:::

[^302]: If you are interested in learning more about this, an 
[article in Science](https://www.sciencemag.org/news/2020/04/antibody-surveys-suggesting-vast-undercount-coronavirus-infections-may-be-unreliable) 
provides an overview of the controversy, and a 
[blog post by statistician Andrew Gelman](https://statmodeling.stat.columbia.edu/2020/04/19/fatal-flaws-in-stanford-study-of-coronavirus-prevalence/) 
provides a thorough discussion 
of the statistical issues.

## Chapter review {-#review-probability}

In this chapter we have learned the basic terminology and concepts of probability. You
may have seen a number of these terms and ideas in high school, but we are approaching
them at a higher level. Be sure to review these terms and concepts in detail, and
do the practice problems to test your knowledge.

Our next step is to take our general framework of outcomes and events, and apply
them to [random variables](#random-variables) - outcomes that are specifically 
numerical.  

## Practice problems {-#problems-probability}

Answers can be found in the [appendix](#answers-probability).

Most of these practice problems will be based on the casino game of *craps*. Craps
is played with a pair of 6-sided dice. 

Players take turns rolling the dice, and the player currently rolling the dice
is called the "shooter".  There are various bets - pass, don't
pass, come, don't come, field, place, buy - that can be placed on the
results of multiple rolls of the dice.  These bets and their probability 
calculations can be quite complex, so we will focus on "single roll" bets.

- A bet on "Snake Eyes" wins if the total showing on the dice is 2.
- A bet on "Yo" wins if the total showing on the dice is 11.
- A bet on "Boxcars" wins if the total showing on the dice is 12.
- A bet on "Field" wins if the total showing on the dice is 2, 3, 4, 9, 10, 
  11, or 12.

For this example, assume that 

 - One die is red and the other is white. 
 - Both dice are fair, that is each side has equal probability
 - The dice are independent of one another
 
An outcome for a single roll of the dice is a pair of numbers $(r,w)$ 
where $r$ is the amount showing on the red die, and $w$ is the amount
showing on the white die. For example an outcome $(2,4)$ means that the
red die is showing 2 and the white die is showing 4.

**SKILL #1: Define outcomes and sample space for a simple example**

1. Let $\Omega$ be the sample space for the outcome of a single roll in craps.
   a. Define $\Omega$ by enumeration.
   b. Find the cardinality of $\Omega$.
2. Using enumeration, define the following events:
   a. Yo wins
   b. Snake eyes wins
   c. Boxcars wins
   d. Field wins

**SKILL #2: Use set theory to work with events**

3. Which of the following statements are true?
   a. The events "Yo wins" and "Boxcars wins" are identical.
   b. The events "Yo wins" and $(r,w) = (5,6)$ are identical.
   c. The events "Boxcars wins" and $(r,w) = (6,6)$ are identical.
4. Which of the following statements are true?
   a. The events "Yo wins" and "Boxcars wins" are disjoint.
   b. The events "Yo wins" and "Field wins" are disjoint.
   c. The events "Yo wins" and "Boxcars loses" are disjoint.
   d. The events "Yo wins" and "Field loses" are disjoint.
5. Which of the following statements are true?
   a. The event "Yo wins" implies the event "Boxcars wins".
   b. The event "Yo wins" implies the event "Boxcars loses".
   c. The event "Yo wins" implies the event "Field wins".
   d. The event "Yo wins" implies the event "Field loses".
6. Which of the following are elementary events?
   a. Yo wins.
   b. Yo loses.
   c. Boxcars wins.
   d. Boxcars loses.
   e. Field wins.
   f. Field loses.

**SKILL #3: Calculate event probabilities from elementary event probabilities**

7. Calculate each of the following elementary event probabilities:
   a. $(r,w) = (1,1)$
   b. $(r,w) = (3,4)$
   c. $(r,w) = (6,6)$
8. Find the probability of each of the following events:
   a. A bet on Yo wins.
   b. A bet on Snake eyes wins.
   c. A bet on Boxcars wins.
   d. A bet on Field wins.

**SKILL #4: Calculate joint and conditional probabilities**

9. Calculate each of the following joint probabilities:
   a. $\Pr(\textrm{Yo wins} \cap \textrm{Boxcars wins})$
   b. $\Pr(\textrm{Yo wins} \cap \textrm{Field wins})$
   c. $\Pr(\textrm{Yo wins} \cap \textrm{Boxcars loses})$
10. Calculate each of the following conditional probabilities:
    a. $\Pr(\textrm{Yo wins} | \textrm{Boxcars wins})$
    b. $\Pr(\textrm{Yo wins} | \textrm{Field wins})$
    c. $\Pr(\textrm{Yo wins} | \textrm{Boxcars loses})$
    d. $\Pr(\textrm{Field wins} | \textrm{Yo wins})$
    e. $\Pr(\textrm{Boxcars wins} | \textrm{Yo wins})$
11. Which of the following pairs of events are independent?
    a. Yo wins and Boxcars wins.
    b. Yo wins and Field wins.
    c. Yo wins and Yo wins.
    d. $r = 3$ and $r = 5$.
    e. $r = 3$ and $w =5$.

**SKILL #5: Apply the axioms of probability**

12. Let $A$ be an event.  Which of the following statements are true?
    a. $\Pr(A) \geq 0$.
    b. $\Pr(A) > 0$.
    c. $\Pr(A) \leq 1$.
    d. $\Pr(A) < 1$.
    e. $\Pr(A^c) \geq 0$.
    f. $\Pr(A^c) > 0$.
    g. $\Pr(A^c) \leq 1$.
    h. $\Pr(A^c) < 1$.
    i. $\Pr(A^c) = 1 - \Pr(A)$.
13. Let $A$ and $B$ be two events.  Which of the following statements 
    are true?
    a. $\Pr(A \cup B) = \Pr(A) + \Pr(B)$.
    b. $\Pr(A \cup B) = \Pr(A) + \Pr(B) - \Pr(A \cap B)$.
    c. $\Pr(A \cup B) \leq \Pr(A) + \Pr(B)$.
    d. $\Pr(A \cap B) = \Pr(A)\Pr(B)$.
14. Let $A$ and $B$ be two disjoint events.  Which of the following
    statements are true?
    a. $\Pr(A \cap B) = 0$.
    b. $\Pr(A \cap B) = \Pr(A) + \Pr(B)$.
    c. $\Pr(A \cup B) = 0$.
    d. $\Pr(A \cup B) = \Pr(A) + \Pr(B)$.
    e. $\Pr(A \cup B) = \Pr(A) + \Pr(B) - \Pr(A \cap B)$.
    f. $\Pr(A \cup B) \leq \Pr(A) + \Pr(B)$.
    g. $\Pr(A \cap B) = \Pr(A)\Pr(B)$.
    h. $\Pr(A | B) = 0$
15. Let $A$ and $B$ be two events such that $A \subset B$.  Which of 
    the following statements are true?
    a. $\Pr(A) \leq \Pr(B)$
    b. $\Pr(A \cap B) = \Pr(A)$
    c. $\Pr(A | B) = 1$
16. Let $A$ and $B$ be two independent events.  Which of the following
    statements are true?
    a. $\Pr(A \cap B) = 0$.
    b. $\Pr(A \cap B) = \Pr(A)\Pr(B)$.
    c. $\Pr(A|B) = \Pr(A)$.

