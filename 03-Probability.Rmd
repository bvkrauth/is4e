# Probability and random events {#probability-and-random-events}

***Probability*** is a method of mathematically modeling a random process
so that we can understand it and/or make predictions about its future 
results. Probability is an essential tool for casinos, as well as for
banks, insurance companies, and any other businesses that manage risks.

::: goals
**Chapter goals**

In this chapter we will learn how to:

 - Model random events using the tools of probability
 - Calculate and interpret marginal, joint, and conditional probabilities
 - Interpret and use the assumptions of independence and equal outcome probability
:::

This chapter uses mathematical notation and terminology that you
have seen before but may need to review.  If you have difficulty with
the math, please refer to the sections on [Sets](#sets) and on [Functions](#sets) in the [Math Review](#math-review) appendix.

::: example
**Example application: Roulette**

We will develop ideas by considering the casino game of **Roulette**.
The picture below shows what a roulette wheel looks like.

![roulette wheel image](bin/roulette.png)
Source: <a href="https://www.vecteezy.com/free-vector/roulette">Roulette Vectors by Vecteezy</a>

Here are the rules:

- It features 
  - a ball.
  - a spinning wheel with numbered/colored slots. 
  - a table on which to place bets
- The slots are numbered from 0 to 36
  - Slot number 0 is green
  - 18 slots are red
  - 18 slots are black.
  - The picture above depicts an American roulette table, which has an 
    additional green slot labeled "00",
  - I will assume we have a European roulette table, which does not include
    the "00" slot.
- Players can place various bets on the table including:
  - Red (ball lands in a red slot) pays \$1 per \$1 bet
  - Black (ball lands in a black slot) pays \$1 per \$1 bet
  - A straight bet on any specific number (ball lands on that number)
    pays \$35 per \$1 bet

Like other casino games, a roulette game is an example of a random process.
Something will happen, it matters (to the players and the casino) what
will happen, but we don't know in advance what will happen.
:::

## Outcomes and events

To build a probabilistic model of a random process, we start by defining
the ***outcome*** we are interested in.  An outcome can be a simple yes/no
result, it can be a number, or it can be a much more complex object. The
outcome should be a complete description of the random process, in the
sense that everything we are interested in can be defined in terms of
the outcome.

::: example
**Outcomes in roulette**

The outcome of a single game of roulette can be defined as the number of 
the slot in which the ball lands.  Call that number $b$.
:::

The set of all possible outcomes is called the ***sample space***

::: example
**The sample space in roulette**

The sample space for a game of roulette can be defined as
the set of all numbers the ball can land on:
   $$\Omega = \{0,1,2,\ldots,36\}$$
This sample space has $|\Omega| = 37$ elements.
:::

Next, we define a set of ***events*** that we are interested in.
We can think of an event as either:

 - A statement that is either true or false OR
 - A subset of the sample space 

These two concepts are equivalent, though the subset concept 
makes the math clearer.
 
::: example
**Events in roulette**

These roulette events are well-defined for our sample space: 

- Ball lands on 14:
  $$b \in \{14\}$$
- Ball lands on red:
   $$b \in Red = \{1,3,5,7,9,12,14,16,18,19,21,23,25,27,30,32,34,36\}$$
- Ball lands on black:
   $$b \in Black = \{2,4,6,8,10,11,13,15,17,20,22,24,26,28,29,31,33,35\}$$
- Ball lands on one of the first 12 numbers:
   $$b \in First12 = \{1,2,3,4,5,6,7,8,9,10,11,12\}$$

We could define many more events, depending on what bets
we are interested in.
:::

Since events are sets, we can use the terminology and mathematical
tools for sets. 

::: example
**Relationships among events**

In our roulette example:

- Events are *identical* if they contain exactly the same outcomes:
  - The event "ball lands on 14" and "a bet on 14 wins"
    are identical since $\{14\} = \{14\}$.
  - Intuitively, identical means they are just two different ways of describing
    the same event.
- An event *implies* another event if all of its outcomes are also in 
  the implied event 
  - The event "ball lands on 14"  implies the event "ball lands on red" 
    since $\{14\} \subset Red$.
  - When an event happens, any event it implies also happens.
- Events are *disjoint* if they share no outcomes:
  - The events "ball lands on red" and "ball lands on black" are disjoint 
    since $Red \cap Black = \emptyset$.
  - If two events are disjoint, they cannot both happen.
  - But they can both fail to happen.  For example, if the ball lands in the
    green zero slot ($b = 0$), neither red nor black wins.
- Any two outcomes are either identical or disjoint
   - The events "ball lands on 14" and "ball lands on 25" are disjoint
     since $\{14\} \cap \{25\} = \emptyset$.
:::

## Probabilities

Our final step is to define a ***probability distribution***
for this random process, which is a function that assigns
a number to each possible event.  The number is called 
the event's ***probability***. 

Probabilities are normally between zero and one:

- If an event has probability zero, it definitely *will
  not* happen
- If an event has probability strictly between zero and
  one, it *might* happen.
- If an event has probability one, it definitely *will* 
  happen.

### The axioms of probability

All valid probability distributions must obey the following three conditions:

1. Probabilities are never negative:
   $$\Pr(A) \geq 0$$
2. One of the outcomes will definitely happen:
   $$\Pr(\Omega) = 1$$
3. For any two *disjoint* events $A$ and $B$, the probability that
   $A$ or $B$ happen is the sum of their individual probabilities:
   $$\Pr(A \cup B) = \Pr(A) + \Pr(B)$$

These conditions are sometimes called the ***axioms*** of probability.
Probability distributions have many other properties, but they
can all be derived from these three.

::: example
**Outcome probabilities for a fair roulette game**

Let's assume that the roulette wheel is "fair" in the sense that each 
outcome has the same probability. Now, I should emphasize that this 
doesn't have to be the case, it's just an assumption.  But it's a 
reasonable one in this case because casinos are required
by law to run fair roulette wheels and would be subject to heavy 
penalties if they run unfair wheels. Later on, we will use statistics
to confirm that a roulette wheel is fair.

Call that probability $p$:
   $$p = \Pr(b = 0) = \Pr(b = 1) = \cdots = \Pr(b = 36)$$
To find the value of $p$ we use the rules of probability. 
By rule #2 of probability, one of the outcomes will happen:
   $$\Pr(\Omega) = 1$$
Since the different outcomes are disjoint, rule #3 implies that:
   $$\underbrace{\Pr(\Omega))}_{1} = \underbrace{\Pr(\{0\})}_{p} + \underbrace{\Pr(\{1\})}_{p} + \cdots + \underbrace{\Pr(\{36\})}_{p}$$
Summarizing this equation:
   $$1 = 37p$$
Solving for $p$ we get:
   $$p = 1/37 \approx 0.027$$
That is, each of the 37 outcomes have a probability of $1/37$.
:::

Since this is an introductory course, our sample space will usually 
contain a finite number of outcomes, as in our roulette example.  In
that case, probability calculations are pretty simple:

- Find the probability of each outcome.
- To find the probability of a specific event, just add up the probabilities
  of its outcomes.
  

::: example
**Event probabilities for a fair roulette game**

In the roulette example, the probability of any event $A$ is just the number
of outcomes in $A$ times the probability of each outcome $1/37$:
   $$ \Pr(A) = |A|*1/37$$
The notation $|A|$ just means the size of (number of elements in) the set $A$.

For example:
$$\Pr(b=25) = |\{25\}|*1/37 = 1/37 \approx 0.027$$
$$\Pr(Red) = |Red|*1/37 = 18/37 \approx 0.486$$
$$\Pr(Even) = |Even|*1/37 = 18/37 \approx 0.486$$
$$\Pr(First12) = |First12|*1/37 = 12/37 \approx 0.324$$
:::

However, not all sample spaces contain a finite number of outcomes.  For
example, suppose we are interested in using probability to model the
unemployment rate, or a person's income.  Those are real numbers, and can 
take on any of an infinite number of values.  This adds a few complications,
and is the reason that the probability axioms refer to events (sets of
outcomes) and not individual outcomes.

::: fyi
**What do probabilities really mean?**

What does it really mean to say that the probability of the ball landing in 
a red slot is about 0.486? That's actually a tough question. There
are two standard interpretations for probabilities:

- *Frequentist or classical interpretation*: we are thinking of 
  the random process as something that could be repeated many times,
  and the probability of an event is the approximate fraction of times
  that the event will occur.  That is, if you go to a casino and
  bet 1000 times on Red, you will win about 486 times. 
- *Bayesian or subjectivist interpretation*: the random process
  is a one-time occurrence, but we have limited information about
  it and the probability of event represents the strength of 
  our belief that the event will happen.

The frequentist interpretation of probability is well-suited
for simple repeated settings like casino games or car insurance,
while the Bayesian interpretation makes more sense for things
like predicting election results.
:::


## Related events

We are often interested in more than one event, and want to talk about how 
they are related. For example:

 - In some casino games like poker or blackjack, players take an additional 
   action after partial information about the outcome is revealed.
 - Politicians often use polls to predict the winner of an election.
 - Finance people often want to model multiple market scenarios and 
   forecast a company's earnings under each of them.
 - Economists often have data on current economic conditions and want 
   to predict future economic conditions.

This section will develop some tools for dealing with the relationship
between different random events.

### Some rules for probabilities

Let $A$ and $B$ be two events.  Then our three axioms
of probability imply several additional rules:

- Probabilities cannot be higher than one.
   $$\Pr(A) \leq 1$$
- Probabilities of identical events are identical:
   $$A = B \implies \Pr(A) = \Pr(B)$$
- Probabilities of implied events are larger:
   $$A \subset B \implies \Pr(A) \leq \Pr(B)$$
- The probability of an event *not* happening is:
   $$\Pr(A^C) = 1 - \Pr(A)$$
- The probability of nothing happening is:
   $$\Pr(\emptyset) = 0$$
- The probability of either $A$ or $B$ happening is:
  \begin{align}
    \Pr(A \cup B) &= \Pr(A) + \Pr(B) - \Pr(A \cap B) \\
      &\leq \Pr(A) +\Pr(B)
  \end{align}

These results are not hard to prove, but I will not go through the proofs.
However, I will use these results so you should be familiar with them.

### Joint probabilities

The ***joint probability*** of two events $A$ *and* $B$ is the probability that
they *both* happen:
  $$\Pr(A \cap B)$$
Remember that the intersection ($\cap$) of $A$ and $B$ is the set of all 
outcomes that are in both $A$ and $B$.

::: example
**Joint probabilities for roulette bets**

Consider two events for a game of roulette:
  $$Red = \{1,3,5,7,9,12,14,16,18,19,21,23,25,27,30,32,34,36\}$$
  $$Even = \{2,4,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36\}$$
Suppose you are interested in the probability that the ball lands on a number that is both 
red and even. 
  $$\Pr(Red \cap Even) = \Pr(\{12,14,16,18,30,32,34,36\}) = 8/37 \approx 0.216$$
:::

Joint probabilities are just probabilities, so they obey all of the rules of probability.  For example, all joint probabilities are between zero and one.

### Conditional probabilities

The ***conditional probability*** of an event $A$ ***given*** another
event $B$ is defined as:
   $$\Pr(A|B) = \frac{\Pr(A \cap B)}{\Pr(B)}$$
The conditional probability answers the question: if we already know that 
$B$ is true, what are the chances that $A$ is true?

Conditional probabilities are very important when playing poker. At the beginning
of the game, every player has equal chance of having a winning hand.
But that is no longer true after you see your cards - having "good" cards increases
your chance of winning, and having "bad" cards decreases that chance. In other
words, your bet should be based on $\Pr(win|cards)$ rather than $\Pr(win)$. Good
poker players have detailed knowledge of these conditional probabilities.

::: example
**Conditional probabilities in roulette**

In our roulette example:
   $$\Pr(Red|Even) = \frac{\Pr(Red \cap Even)}{\Pr(Even)} = \frac{8/37}{18/37} \approx 0.444$$
   $$\Pr(b = 14|Even) = \frac{\Pr(b = 14 \cap Even)}{\Pr(Even)} = \frac{1/37}{18/37} \approx 0.056$$
:::

Like joint probabilities, conditional probabilities are just probabilities,
so they obey all of the rules of probability.

### Independent events 

One common "trick" in modeling joint and conditional probabilities is to assume
that certain events are unrelated to each other. This can simplify the math
significantly.

We say that two events $A$ and $B$ are ***independent*** if their joint
probability is just the two individual probabilities multiplied together:
  $$\Pr(A \cap B) = \Pr(A)\Pr(B)$$
We usually express independence with the notation $A \bot B$.

::: fyi
**Events are not always independent**

A common mistake by students who are new to probability and
statistics is to take results that *only* apply under independence
and use them when there is no reason to believe that independence
holds.

Don't make this mistake: independence is an assumption, and one that
can easily be incorrect.
:::

The definition of independence is not very intuitive, but we can clarify
it by doing a little math.  Consider two independent events $A$
and $B$ that have nonzero[^301] probability.  Then by the definition of
independence:
  $$\Pr(A|B) = \frac{\Pr(A \cap B)}{\Pr(B)} = \frac{\Pr(A)\Pr(B)}{\Pr(B)} = \Pr(A)$$
By the same reasoning:
  $$\Pr(B|A) = \Pr(B)$$
In other words, knowing that one of these events are true 
tells you nothing useful about whether the other the other event
is true.

[^301]: You may wonder: if it makes more sense to describe independence 
      in terms of conditional probabilities, why do we define it in 
      terms of joint probabilities?  The key is the requirement that
      the events have nonzero probability. When $B$ has zero
      probability the conditional probability $\Pr(A|B)$ is not
      well defined since its denominator is zero.

::: example
**Independence in a roulette game**

Consider the roulette events "Red wins" and "Even wins".  We earlier
showed that the unconditional probability that Red wins is:
  $$\Pr(Red) = 18/37 \approx 0.486$$
The conditional probability that Red wins given that Even wins is:
   $$\Pr(Red|Even) = 8/18 \approx 0.444$$
Since $0.44 \neq 0.486$, these two events are *not* independent.
:::

When would it be reasonable to assume events are independent? 
The typical scenario would be where there is simply no 
physical or logical relationship between them, usually due
to a separation in time and space.

::: example
**Independence across roulette games**

We have already shown that events related to a *single* roulette game
are not necessarily independent.  But the outcomes/events of 
*two different* roulette games can be reasonably assumed to be independent
of one another.

Suppose that I bring \$100 to a casino this afternoon for a few games 
of roulette. I bet all of my money on Red for the first game.

- If I lose, I am broke and stop playing.
- If I win, I keep all of my money (both my initial bet and my winnings)
  on Red for the next spin.  
- I keep playing until I run out of money.

After 3 games:

 - If Red wins all 3 games, I have $w = \$800$.
 - Otherwise, I have nothing $w = \$0$

What is the probability of each of these events?  Since we can 
assume that each game's outcome is independent, this is an easy
problem:
  \begin{align}
    \Pr(w = \$800) &= \Pr(Red_1 \cap Red_2 \cap Red_3) \\
      &= \Pr(Red_1) \times \Pr(Red_2) \times \Pr(Red_3) (\#eq:indep) \\
      &= (18/37) \times (18/37) \times (18/37) \approx 0.115 \\
    \Pr(w = \$0) &= 1 - \Pr(w = \$800) \\
      &\approx 0.885 \\
  \end{align}
So we have an 11.5\% chance of winning big, and an 88.5\% chance
of going broke.

Very important: equation \@ref(eq:indep) only follows from the previous
equation because we have assumed the events $Red_1$, $Red_2$, and $Red_3$
are independent.
:::

### Two "laws" of probability

In addition to the results we have already discussed, there are two
important results using conditional probabilities:

The first is the ***law of total probability*** which
is a rule for determining unconditional probabilities 
from conditional probabilities:

  $$\Pr(A) = \Pr(A|B)\Pr(B) + \Pr(A|B^c)\Pr(B^c)$$

The law of total probability allows us to create a set of scenarios,
calculate probabilities under each scenario, and then add them up. It 
is useful when we are modeling random outcomes that occur in multiple
stages, for example a poker game or an energy company making a series of
investments to develop an oil field.

The second is ***Bayes' law***, which is a rule for determining 
conditional probabilities:
  $$\Pr(A|B) = \frac{\Pr(B|A)\Pr(A)}{\Pr(B)}$$
Bayes' law is particularly useful in evaluating evidence, because
it allows us to restate one conditional probability in terms of
another.  

Both the law of total probability and Bayes' law follow from the definition of
conditional probabilities.  They are easy to prove, but I won't prove them
here.  Instead, I will use an example to show how they can be useful.

::: example
**False positives in medical testing**

When someone is tested for a disease, the test comes back either
"positive" (the person has the disease) or "negative" (the person does
not have the disease). However, no test is perfect. Sometimes people
who do not have the disease test positive ("false positives") and 
sometimes people who do have the disease test negative 
("false negative").

Let the event $T$ mean a particular patient tests positive
for a disease, and let the event $D$ mean that this patient 
actually has the disease. 

The *sensitivity* of the test is an infected patient's probability
of testing positive:
   $$\Pr(T|D) = p$$
the *specificity* of the test is a healthy patient's probability
of testing negative:
   $$\Pr(T^c|D^c) = q$$
and the *prevalence* of the infection is the probability that
a given patient has the disease:
   $$\Pr(D) = d$$
Suppose that a patient has tested positive.  What is the
probability that he has the disease, i.e. what the value of
$\Pr(D|T)$?

This is a classic probability question, as it makes use
of Bayes' law and the law of total probability, and it has
obvious practical usage.  

Since we want a conditional probability, we start by stating Bayes' law:
   $$\Pr(D|T) = = \frac{\Pr(T|D)\Pr(D)}{\Pr(T)}$$
Bayes' law will allow us to calculate $\Pr(D|T)$ if we can find 
the components of the right side of this equation. 
We already know that $\Pr(T|D)=p$ and $\Pr(D)=r$, so all we need 
is to find $\Pr(T)$.

Since $\Pr(T)$ is an unconditional probability, we can use
the law of total probability:
   $$\Pr(T) = \underbrace{\Pr(T|D)}_{p}
              \underbrace{\Pr(D)}_{d} 
            + \underbrace{\Pr(T|D^c)}_{1-q}
              \underbrace{\Pr(D^c)}_{1-d}$$
Plugging these results into our formula we get:
   $$\Pr(D|T) = = \frac{pd}{pd + (1-q)(1-d)}$$
which is the result we need.

Now, let's try out some numbers.  Suppose that false positives are rare 
($q = 0.99$), and false negatives never happen ($p=1$).

- Suppose the disease itself is fairly common ($d = 0.10$).  Then:
   $$\Pr(D|T) = = \frac{1*0.1}{1*0.1 + (1-0.99)*(1-0.1)} \approx 0.917$$
- Suppose the disease itself is quite rare ($d = 0.001$).  Then
   $$\Pr(D|T) = = \frac{1*0.001}{1*0.001 + (1-0.99)*(1-0.001)} \approx 0.091$$

In other words, the exact same test has a very different meaning depending
on the prevalence in the population: when the disease is common a positive
test means a 91.7% chance of having the disease, and when the disease
is rare a positive test result means a 9.1% chance of having the disease.

This general issue (even a small false positive rate can have a big impact
when prevalence is low) appeared repeatedly in March and April of 2020. Several 
studies by well-known researchers[^302] dramatically overestimated the early
prevalence of the COVID-19 virus and thus dramatically underestimated its
fatality rate. These studies were regularly cited as support by those who 
wanted to substantially relax public health restrictions in April 2020,
and had substantial real world consequences.
:::

[^302]: If you are interested in learning more about this, an 
[article in Science](https://www.sciencemag.org/news/2020/04/antibody-surveys-suggesting-vast-undercount-coronavirus-infections-may-be-unreliable) 
provides an overview of the controversy, and a 
[blog post by statistician Andrew Gelman](https://statmodeling.stat.columbia.edu/2020/04/19/fatal-flaws-in-stanford-study-of-coronavirus-prevalence/) 
provides a thorough discussion 
of the statistical issues.
