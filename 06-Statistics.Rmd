# Statistics

So far, we have learned how to model random events and random numbers, 
and we have learned how to calculate some commonly-used statistics from 
data.  This chapter ties all of that work together.

::: goals
***Chapter goals***

In this chapter we will:

- Use the theory of probability and random variables to model the random
  process generating our data set and the statistics we have calculated 
  from it.
- Apply and interpret the assumption of simple random sampling, and compare
  it to other sampling schemes.
- Calculate and interpret the mean and variance of a statistic from
  its sampling distribution.
- Calculate and interpret bias and mean squared error.
- Explain the law of large numbers, central limit theorem, and Slutsky's 
  theorem.
:::

## Multiple random variables

We will often be interested in the relationship between two or more
random variables. For example, we might want to know how tax rates
are related to economic growth, or how education is related to 
income.

### Joint distributions

Let $x = x(b)$ and $y = y(b)$ be two random variables
defined in terms of the same underlying outcome $b$.
Their joint probability distribution assigns a probability
to every event that can be defined in terms of $x$ and $y$,
for example $\Pr(x = 6 \cap y = 0)$ or $\Pr(x < y)$.

This joint distribution can be fully described by the 
***joint CDF***
$$F_{x,y}(a,b) = \Pr(x \leq a \cap y \leq b)$$
It can also be described by the ***joint PDF***
$$f_{x,y}(a,b) = \begin{cases}
      \Pr(x = a \cap y = b) & \textrm{if $x$ and $y$ are discrete} \\
      \frac{\partial F_{x,y}(a,b)}{\partial a \partial b} & \textrm{if $x$ and $y$ are continuous} \\
      \end{cases}$$

The joint distribution tells you about the relationship between the
two variables as well as the characteristics of the variables themselves.
That is, we can always get the ***marginal*** distributions of the two 
individual random variables from their joint distribution:
$$F_x(a) = \Pr(x \leq a) = \Pr(x \leq a \cap y \leq \infty) = F_{x,y}(a,\infty)$$
$$F_y(b) = \Pr(y \leq n) = \Pr(x \leq \infty \cap y \leq b) = F_{x,y}(\infty,b)$$
However, it is not possible to get the joint distribution from the 
marginal distributions.

::: example
**The joint PDF in roulette**

In our roulette example, the joint PDF of $w_{red}$ and 
$w_{14}$ can be derived from the original outcome.

If $b=14$, then both red and 14 win:
  \begin{align}
    f_{red,14}(1,35) &= \Pr(w_{red}=1 \cap w_{14} = 35) \\
      &= \Pr(b \in \{14\}) = 1/37
  \end{align}
If $b \in Red$ but $b \neq 14$, then red wins but 14 loses:
  \begin{align}
    f_{red,14}(1,-1) &= \Pr(w_{red} = 1 \cap w_{14} = -1) \\
      &= \Pr\left(b \in \left\{
        \begin{gathered}
          1,3,5,7,9,12,16,18,19,21,\\
          23,25,27,30,32,34,36
        \end{gathered}\right\}\right)  \\
      &= 17/37
  \end{align}
Otherwise both red and 14 lose:
  \begin{align}
    f_{red,14}(-1,-1) &= \Pr(w_{red} = -1 \cap w_{14} = -1) \\
      &= \Pr\left(b \in \left\{
        \begin{gathered}
          0,2,4,6,7,10,11,13,15,17, \\
          20,22,24,26,28,31,33,35
        \end{gathered}\right\}\right)  \\
      &= 19/37
  \end{align}
All other values have probability zero.
:::

### Conditional distributions

Having defined joint distributions, we can now define conditional 
distributions. By the definition of a conditional probability:
$$\Pr(x \in A| y \in B) = \frac{\Pr(x \in A \cap y \in B)}{\Pr(y \in B)}$$
So we can define the conditional CDF:
  $$F_{y|x}(a,b) = \Pr(y \leq a|x=b)$$
Conditional distributions can be derived from the joint distribution,
but it isn't always easy.

::: example
**Conditional PDFs in roulette**

Let's find the conditional PDF of the payout for a bet on 
14 given the payout for a bet on red. 
  \begin{align}
    \Pr(w_{14}=-1|w_{red}=-1) &= \frac{\Pr(w_{14}=-1 \cap w_{red}=-1)}{\Pr(w_{red}=-1)} \\
      &=\frac{19/37}{19/37} = 1 \\
  \Pr(w_{14}=35|w_{red}=-1) &= \frac{\Pr(w_{14}=35 \cap w_{red}=-1)}{\Pr(w_{red}=-1)} \\
    &=\frac{0}{19/37} = 0 \\
  \Pr(w_{14}=-1|w_{red}=1) &= \frac{\Pr(w_{14}=-1 \cap w_{red}=1)}{\Pr(w_{red}=1)} \\
    &= \frac{17/37}{18/37} \approx 0.944 \\
  \Pr(w_{14}=35|w_{red}=1) &= \frac{\Pr(w_{14}=35 \cap w_{red}=1)}{\Pr(w_{red}=1)} \\
    &= \frac{1/37}{18/37} \approx 0.056
  \end{align}
:::

### Independence

We say that $x$ and $y$ are ***independent*** if every event defined in 
terms of $x$ is independent of every event defined in terms of $y$.
  $$\Pr(x \in A \cap y \in B) = \Pr(x \in A)\Pr(y \in B)$$
Independence allows us to write all joint and conditional probabilities
in terms of marginal probabilities:
  $$F_{x,y}(a,b) = F_x(a)F_y(b)$$
  $$F_{y|x}(a,b) = F_y(a)$$
As with independence of events, this will be very handy in simplifying the
analysis.  But remember: independence is an *assumption* that
we can only make when it's reasonable to do so.

::: example
**Independence in roulette**

The winnings from a bet on red ($w_{red}$) and the winnings from 
a bet on 14 ($w_{14}$) in the same game are *not* independent. However
the winnings from a bet on red and a bet on 14 in two different 
games *are* independent since the underlying outcomes are independent.
:::

### Covariance and correlation

We earlier showed that if $x$ is a random variable, we can take the
expected value of any function of $x$.  In addition, when $x$ and 
$y$ are random variables with a well-defined joint distribution, 
we can take the expected value of any function of $x$ and $y$.

When $x$ and $y$ are both discrete:
  $$E(g(x,y)) = \sum_{a \in S_x} \sum_{b \in S_y} g(a,b)\Pr( x=a \cap y = b)$$
That is, we add up $g(x,y)$ across all possible values for the pair $(x,y)$
with each value weighted by its probability.

::: fyi
When $x$ and $y$ are both continuous:
  $$E(g(x,y)) = \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} g(a,b)f_{x,y}(a,b)dadb$$
Again, this looks similar to the formula for the discrete case,
but uses an integral instead of a sum.
:::

As with a single random variable, you can take the expected value inside
a linear function:
  $$E(ax + by + c) = aE(x) + bE(y) + c$$
but not inside most other functions.  For example:
  $$E(xy) \neq E(x)E(y)$$
  $$E(x/y) \neq E(x)/E(y)$$
etc.

::: example
**Multiple bets in roulette**

Suppose we bet \$100 on red and \$10 on 14. Our net payout will be:
  $$w_{total} = 100*w_{red} + 10*w_{14}$$
which has expected value:
  \begin{align}
    E(w_{total}) &= E(100 w_{red} + 10 w_{14}) \\
      &= 100 \, \underbrace{E(w_{red})}_{\approx -0.027} + 10 \, \underbrace{E(w_{14})}_{\approx -0.027} \\
      &\approx -3 
  \end{align}
That is we expect this betting strategy to lose an average of 
about \$3 per game.
:::

The ***covariance*** of two random variables $x$ and $y$ 
is defined as:
  $$\sigma_{xy} = cov(x,y) = E[(x-E(x))*(y-E(y))]$$
and their ***correlation*** is defined as:
  $$\rho_{xy} = corr(x,y) = \frac{cov(x,y)}{\sqrt{var(x)var(y)}} = \frac{\sigma_{xy}}{\sigma_x\sigma_y}$$
Both the covariance and correlation are measures of how $x$ and $y$ tend to 
move together.  

- When the covariance or correlation is *positive*, then that means that
  $x$ and $y$ tend to move in the *same* direction. When $x$ is high, $y$ is
  typically high, and when $x$ is low, $y$ is typically low.
- When the covariance or correlation is *negative*, then that means that
  $x$ and $y$ tend to move in *opposite* directions. When $x$ is high, $y$ is
  typically low, and when $x$ is low, $y$ is typically high.
- When the covariance or correlation is *zero* or close to zero, 
  then that means that $x$ and $y$ tend *not* to move together.
- Since the standard deviations $\sigma_x$ and $\sigma_y$ are always[^3]
  positive, the covariance and correlation always have the same sign.
- When $x$ and $y$ are independent, their covariance and correlation
  are both exactly zero.  
  - However, it does not go the other way around.  There are many
    pairs of random variables that have a correlation of zero but
    are not independent.
- The covariance always lies somewhere between $-\sigma_x\sigma_y$ and
  $\sigma_x\sigma_y$, and so the correlation always lies between 
  $-1$ and $1$.
  
[^3]: More precisely, one or both of $\sigma_x$ and $\sigma_y$ could be zero.
In that case the covariance will also be zero, and the correlation will be 
undefined (since it is zero divided by zero).

::: example
**Covariance and correlation in roulettte**

The covariance of $w_{red}$ and $w_{14}$ is:
  \begin{align}
    cov(w_{red},w_{14}) &= \begin{aligned}[t]
        & (1-\underbrace{E(w_{red})}_{\approx -0.027})(35-\underbrace{E(w_{14})}_{\approx -0.027})\underbrace{f_{red,14}(1,35)}_{1/37}\\
        &+ (1-\underbrace{E(w_{red})}_{\approx -0.027})(-1-\underbrace{E(w_{14})}_{\approx -0.027})\underbrace{f_{red,14}(1,-1)}_{17/37} \\ 
        &+ (-1-\underbrace{E(w_{red})}_{\approx -0.027})(-1-\underbrace{E(w_{14})}_{\approx -0.027})\underbrace{f_{red,14}(-1,-1)}_{19/37} \\
        \end{aligned} \\
      &\approx 0.999 
    \end{align}
and its correlation is:
  \begin{align}
    corr(w_{red},w_{14}) 
    &= \frac{cov(w_{red},w_{14})}{\sqrt{var(w_{red})*var(w_{14})}} \\
     &\approx \frac{0.999}{\sqrt{1.0*34.1}} \\
     &\approx 0.17
  \end{align}
:::


The covariance is the expected value of a product, and the expected
value is a sum, which implies several convenient properties:

- The covariance can be written:
  $$cov(x,y) = E(xy) - E(x)E(y)$$
- Covariances of sums can be written:
  \begin{align}
    cov(ax+by+c, dx+ey+f) &= 
    \begin{aligned}[t]
      & ad \, var(x) + be \, var(y) \\
      &+ (bd + ae) \, cov(x,y) \\
    \end{aligned}
  \end{align}
- The variance of a random variable is its covariance with itself:
  $$cov(x,x) = var(x)$$
  
- The variance of a sum can be written:
  $$var(ax+by+c) = a^2 \, var(x) + b^2 \, var(y) + 2ab \, cov(x,y)$$ 

I will occasionally make use of these properties.



## Data and the data generating process

Suppose we have a data set. We would like to use that data set to learn
something about the mechanisms by which the data set was generated.
This process of learning from data is statistical analysis.

The basic idea of statistical analysis is that we will 

- Treat our data as the outcome of a random process called 
  the data generating process or "DGP"
- Create a probabilistic model of the DGP
  - This model typically includes one or more unknown 
    features called parameters.
  - Both the data itself and any numbers (statistics) calculated from that 
    data can be considered random variables whose probability distribution
    could be derived from the DGP *if we knew the DGP*.
- Construct statistics to estimate the unknown parameters of the DGP.
  - We will want to use statistics that have a high probability of 
    prividing provide accurate estimates. 

Given this overall strategy, we can talk about the details.

### A general framework

Let $D_n$ be our data set.  We think of $D_n$ as a set of random variables 
with unknown joint distribution $P_D$.  This joint distribution
is called the ***data generating process*** for $D_n$. The exact DGP
is assumed to be unknown, but we usually have at least some information 
about it.

In this chapter we will assume that $D_n = (x_1,x_2,\ldots,x_n)$ 
is a data set with one variable and $n$ observations.  We 
use $x_i$ to refer to an arbitrary observation $i$.

::: example
Returning to our roulette example, suppose our data provides
the result of 3 independent games of roulette.  Let $b_i$ 
be the outcome in game $i$, and let $x_i$ be the result of 
a bet on red:
  $$x_i = I(b_i \in RED) = \begin{cases} 1 & b_i \in RED \\ 0 & b_i \notin RED \\ \end{cases}$$
Then $D_n = (x_1,x_2,x_3)$. For example, if red loses the first
two games and wins the third game we have $D_n = (0,0,1)$.
:::

We have some ***statistic*** $s =s(D_n)$, i.e., a number that is 
calculated from the data.

  - Since the data is observed/known, the value of the statistic
    is observed/known.
  - Since the elements of $D_n$ are random variables, $s$ is also 
    a random variable with a well-defined (but unknown) probability
    distribution that depends on the unknown DGP.

::: example
In our roulette example, the total number of wins is:
  $$s = x_1 + x_2 + x_3$$
Since this is a number calculated from our data, it is a statistic.
:::

Often we are interested in some ***parameter*** $\theta = \theta(P_D)$ that 
describes some aspect of the DGP.  
  
  - Since the exact DGP is unknown, the exact value of $\theta$ is also
    unknown. 

::: example
In previous chapters, I asked you to assume that the roulette wheel
was *fair*, meaning that all outcomes were equally likely.  This 
allowed us to calculate the exact probability of red winning. But 
that is not possible in every application of probability:

- Maybe the roulette wheel isn't actually fair.
- Maybe the probability of a given event is actually quite 
  difficult to calculate exactly.

In either of these cases, it makes more sense to treat the
probability of winning as an unknown parameter:
  $$\theta = \Pr(x_i = 1)$$
Once we know this parameter, we can calculate the exact 
probability distribution of our data.

This calculation is time-consuming and not particularly informative,
but here is what it looks like.  The probability of observing 
a particular value of $D_n$ is:
  $$\Pr(D_n) = \theta^{s(D_n)}(1-\theta)^{3-s(D_n)}$$
where $s(D_n)=x_1+x_2+x_3$.
:::

We may use our statistic $s$ to tell us something about the value
of $\theta$:

  - Estimation: we may use $s$ as a best guess or ***estimate*** of 
    the true value of $\theta$.
  - Inference: we may use $s$ to infer whether a particular value
    of $\theta$ is plausible.

::: example
In our roulette example, a natural guess of the probability of red 
winning is the number of times we observe it winning.  That is,
if red wins about half of the time, we guess that it has about
a 50\% probability of winning. 

Alternatively, suppose we play 100 games of roulette and observe that red 
never wins (or always wins).  We might suspect that the casino is not 
running a fair table!
:::

In this chapter we will focus on estimation.  We will cover statistical
inference in a later chapter.

### Simple random sampling

In order to model the data generating process, we need to
model the entire joint distribution of $D_n$.  This
means:

- The probability distribution of each $x_i$
- The relationship between each of the $x_i$'s

Fortunately, we often can simplify this joint distribution
quite a bit by assuming that $D_n$ 
is ***independent and identically distributed*** (IID) 
or a ***simple random sample*** from a large ***population***.

A simple random sample has two features:

1. Independent: Each $x_i$ is independent of the others.
2. Identically distributed: Each $x_i$ comes from the same (unknown)
  probability distribution.

The reason we call this "independent and identically distributed"
is hopefully obvious, but what does it mean to say we have a 
"random sample" from a "population"? Well, one simple way of 
generating an IID sample is to:

1. Define the population of interest, for example all Canadian 
  residents.
2. Use some purely random mechanism to choose a small subset of cases
  from this population.
   - The subset is called our ***sample***
   - "Purely random" here means some mechanism like a coin flip
     or a computer's random number generator.
   - As a technical matter, the assumption of independence requires
      that we sample *with replacement*. This means we allow
      for the possibility that we sample the same case more than once.
      In practice this doesn't matter as long as the sample is small 
      relative to the population.
3. Collect data from every case in our sample.

It will turn out that a moderately-sized random sample provides 
surprisingly accurate information on the underlying population.

#### Sample selection and representativeness

In the real world, a simple random is quite difficult to collect
from humans. Even if we are able to randomly select cases, we often
run into the following problems:

- ***Nonresponse*** occurs when a sampled individual does not provide
  the requested information:
  - ***Survey-level*** nonresponse occurs when the sampled individual does not
    answer any questions. This can occur if the sampled individual cannot
    be found, refuses to answer, or cannot answer (for example, is
    incapacitated due to illness or disability).
  - ***Item-level*** nonresponse occurs when the sampled individual does 
    not answer a particular question.  This can occur if the respondent
    refuses to answer, or the question is not applicable or has no
    valid answer.
- ***Censoring*** occurs when a particular quantity of interest cannot be
  observed for a particular case.  Censored outcomes are extremely common
  in economics, for example:
    - A classic example of censoring is the market wage for individuals 
      who are not currently employed. 
    - In supply/demand analysis, we only observe quantity supplied and
      quantity demanded at the current market price.
      
Each of these data problems affect whether our sample can be interpreted
as ***representing*** the population we care about. There are two basic
solutions to these problems:

- Imputation: we assume values for all missing quantities. For example,
  we might assume that the wage of each non-employed worker is equal
  to the average wage among employed workers with similar 
  characteristics.
- Redefine the population: redefine the population so that our data
  can be correctly interpreted as a random sample from that population.
  For example, instead of having a random sample of *Canadians*, we can
  interpret our data as a random sample of 
  *Canadians who would answer these questions if asked*. 
  
This is not an issue that has a purely technical solution, but requires
careful thought instead.  If we are imputing values, do we believe that
our imputation method is reasonable?  If we are redefining the population,
is that population one we care about?

### Other sampling models

Not all useful data sets come from a simple random sample. For example:

- Some sample designs can be treated as if they were from a simple 
  random sample, or can be handled with minor modifications on
  the techniques used for simple random samples:
  - A ***stratified sample*** is gathered by dividing the population into
    strata based on some observable characteristics, and then randomly
    sampling a predetermined number of cases within each strata. 
      - Most professional surveys are constructed from stratified samples 
        rather than random samples.
      - Stratified sampling is often combined with *oversampling* of 
        some smaller strata. For example, the Labour Force Survey 
        oversamples residents of Prince Edward Island because a
        national random sample would not catch enough PEI residents to
        accurately measure PIE's unemployment rate.
  - A ***cluster sample*** is gathered by dividing the population
    into ***clusters***, randomly selecting some of these clusters, and
    sampling cases within the cluster.  
      - Educational data sets are often gathered this way: we pick a random 
        sample of schools, and then collect data from each student 
        within those schools.
  - A ***census*** gathers data on every case in the population. 
    - For example, we might have data on all 50 US states, or all 
      10 Canadian provinces, or all of the countries of the world. 
    - Data from administrative sources such as tax records or 
      school records often cover the entire population of interest as well. 
    - We typically interpret a census as a random sample from a hypothetical
      population of possible cases.
- Most macroeconomic data are ***time series***; that is they are observations
  of a particular quantity at regularly-spaced points in time.
  Time series have two features that are inconsistent with the random 
  sampling assumption:
    - They usually have clear time trends.  For example, Canada's real 
      GDP has been steadily growing for as long as we have observed it.
      This means that 2010 GDP is drawn from a distribution with a higher
      expected value than the distribution for 1910 GDP.
    - They usually exhibit what is called autocorrelation. Shocks to
      the economy that affect this year's GDP are likely to have 
      a similar (if smaller) effect on next year's GDP.  So the time periods
      close together are more closely related than time periods that 
      are far apart, even after we have accounted for the time trend.

  Time series data sometimes require more advanced techniques
  than we will learn in this class.
- A ***convenience sample*** is gathered by whatever method is convenient.
  - For example, we might gather a survey from people who walk by,
    or we might recruit our friends to participate in the survey.

  Convenience samples are the worst-case scenario; in many cases they
  simply aren't usable for accurate statistical analysis.
 
Many data sets combine several of these elements.  For example,
Canada's unemployment rate is calculated using data from the 
Labour Force Survey (LFS). The LFS is built from a stratified 
sample of the civilian non-institutionalized working-age population 
of Canada. There is also some clustering: the LFS will typically
interview whole households, and will do some geographic clustering
to save on travel costs. The LFS is gathered monthly, and the
resulting unemployment rate is a time series.


## Statistics and their properties

We will use $s = s(D_n)$ as a general notation for some
statistic calculated from the data set $D_n$. We will now
define some of its properties.

::: example
We will also consider four specific examples:

- The ***sample frequency*** or ***relative sample frequency***
  of the event $x_i \in A$ is defined as the proportion of cases
  in which the event occurs:
  $$\hat{f}_A = \frac{1}{n} \sum_{i=1}^n I(x_i \in A)$$
  A closely-related statistic is the ***absolute sample frequency***
  $n\hat{f}_A$ which is the *number* of cases in which the event 
  occurs.
- The ***sample average*** of $x_i$ is defined as: 
  $$\bar{x} = \frac{1}{n} \sum_{i=1}^n x_i$$
- The ***sample variance*** of $x_i$ is defined as: 
  $$s_x^2 = \frac{1}{n-1} \sum_{i=1}^n (x_i - \bar{x})^2$$
  A closely-related statistic is the ***sample standard deviation***
  $s_x = \sqrt{s_x^2}$ which is the square root of the sample variance.
- The ***sample median*** of $x_i$ is defined as:
  $$\hat{m}_x = m: \begin{cases} \hat{f}_{x < m} \leq 0.5 \\ \hat{f}_{x > m} \leq 0.5 \\ \end{cases}$$
:::

### The sampling distribution

Since the data itself is a collection of random variables, any statistic
calculated from that data is also a random variable, with a probability
distribution that can be derived from the DGP. 

::: example
Calculating the exact probability distribution of most statistics is 
quite difficult, but it is easy to do for the sample frequency. Let 
$p =\Pr(x_i \in A)$.
Then:
  $$n\hat{f}_A \sim Binomial(n,p)$$
In other words, we can calculate the exact probability distribution of
the sample frequency using the formula for the binomial distribution.
:::

### The mean and variance

If our statistic has a probability distribution, it (usually) has a mean
and variance as well. 

::: example
**The mean of the sample average**

Let $\mu_x = E(x_i)$ be the mean of $x_i$  Then the mean of $\bar{x}$ is:
$$E(\bar{x}) = E\left( \frac{1}{n} \sum_{i=1}^n x_i\right) = \frac{1}{n} \sum_{i=1}^n E\left( x_i\right) = \frac{1}{n} \sum_{i=1}^n \mu_x = \mu_x$$
This is an important and general result in statistics.
:::

The mean of the sample average is thus identical to the mean of the 
random variable being averaged.  The variance of the sample average
is also closely related to the variance of the random variable being
averaged.


::: example
**The variance of the sample average**

Let $\mu_x = E(x_i)$ be the mean of $x_i$ and let $\sigma_x^2 = var(x_i)$ be 
its variance. Then the variance of $\bar{x}$ is:
$$var(\bar{x}) = cov(\bar{x},\bar{x}) = E\left[\left( \frac{1}{n} \sum_{i=1}^n 
x_i-\mu\right)\left(\frac{1}{n} \sum_{i=1}^n x_i - \mu\right)\right] = \frac{1}{n^2} \sum_{i=1}^n\sum_{j=1}^n E\left((x_i-\mu)(x_j-\mu)\right) = \frac{1}{n^2} \sum_{i=1}^n\sum_{j=1}^n cov(x_i,x_j)$$
$$cov(x_i,x_j) = \begin{cases} \sigma_x^2 & i = j \\ 0 & i \neq j \\ \end{cases}$$ 
so:
$$var(\bar{x}) = \frac{1}{n^2} \sum_{i=1}^n \sigma_x^2 = \frac{n\sigma_x^2}{n^2} = \frac{\sigma_x^2}{n}$$
:::

Other commonly-used statistics also have a mean and variance.

::: example
**The mean and variance of the sample frequency**

Since the absolute sample frequency has the binomial distribution, 
we have already seen its mean and variance.  Let $p = \Pr(x_i \in A)$.
Then $n\hat{f}_A \sim Binomial(n,p)$ and:
  $$E(n\hat{f}_A) = np$$
  $$var(n\hat{f}_A) = np(1-p)$$

Applying the usual rules for expected values, the mean and variance of
the relative sample frequency is:
  $$E(\hat{f}_A) = \frac{E(n\hat{f}_A)}{n} = \frac{np}{n} = p$$ 
  $$var(\hat{f}_A) = \frac{var(n\hat{f}_A)}{n^2} = \frac{np(1-p)}{n^2} = \frac{p(1-p)}{n} $$
:::

### Parameters and estimators

A ***parameter*** is an unknown number characterizing a DGP. 

::: example
Sometimes a single parameter completely describes the DGP:

- If $x_i$ is a random sample from the $Bernoulli(p)$ distribution,
  then $p$ is a parameter.
  
Sometimes a group of parameters completely describe the DGP:

- If $x_i$ is a random sample from the $U(L,H)$ distribution,
  then $L$ and $H$ are both parameters.
  
And sometimes a parameter only partially describes the DGP

- If $x_i$ is a random sample from some unknown distribution
  with unknown mean $\mu_x = E(x_i)$, then $\mu_x$ is a parameter.
- If $x_i$ is a random sample from some unknown distribution
  with unknown median $m_x = q_{0.5}(x_i)$, then $m_x$ is a parameter.
:::

Typically there will be particular parameters whose value we wish
to know.  Such a parameter is called a ***parameter of interest***.
Our model may include other parameters, which are typically called
auxiliary parameters or nuisance parameters. 

An ***estimator*** is a statistic that is being used to ***estimate***
(guess at the value of) an unknown parameter of interest.  The distinction
between estimator and estimate is a subtle one: we use "estimate" when
talking about our statistic as a number calculated for a specific data set
and "estimator" when talking about it as a random variable.

::: example
**Commonly used estimators**

Our four example statistics are commonly used as estimators:

1. The relative sample frequency $\hat{f}_A$ is typically used as an
  estimator of the probability $p_A = \Pr(x_i \in A)$
2. The sample average $\bar{x}$ is typically used as an estimator
  of the population mean $\mu_x = E(x_i)$.
3. The sample variance $s_x^2$ is typically used as an estimator of
  the population variance $\sigma_x^2 = var(x_i)$.
4. The sample median $\hat{m}_x$ is typically used as an estimator of the
  population median $m_x = q_{0.5}(x_i)$. 

:::

Let $s$ be a statistic we are using as an estimator of some parameter 
of interest $\theta$.  We can define its ***error*** as:
  $$err = s - \theta$$
In principle, we want $s$ to be a good estimator of $\theta$, i.e.,
we want $err$ to be as close to zero as possible.  There
are several major complications to keep in mind:

1. Always remember that $err$ is not an inherent property of the
  statistic - it is a property of the relationship between the statistic
  and the parameter of interest. A given statistic may be a good
  estimator of one parameter, and a bad estimator of another parameter.
2. Since $s$ is a random variable with a probability distribution, 
  so is $err$ is also a random variable with a proability distribution. 
3. Since the value of $\theta$ is unknown, the value of $err$ is also 
  unknown.

### Bias and mean squared error

In choosing an estimator, we can consider several criteria.

The first is the ***bias*** of the estimator, which is defined as:
$$bias(s) = E(s - \theta) = E(s) - \theta$$
The bias represents the average error we would expect over multiple
trials. 

Ideally we would want $bias(s)$ to be zero, in which case
we would say that $s$ is an ***unbiased*** estimator of $\theta$.
Note that bias is always defined relative to the parameter we wish 
to estimate, and is not an inherent property of the statistic.

::: example
**Unbiased estimators of the mean**

Consider the sample average $\bar{x}$ in a random sample
as an estimator of the parameter $\mu_x = E(x_i)$. The bias is:
  $$bias(\bar{x}) = E(\bar{x}) - \mu_x = \mu_x - \mu_x = 0$$
That is, the sample average is an unbiased estimator of the population mean.

However, it is not the only unbiased estimator.  For example, suppose we 
simply take the value of $x_i$ in the first observation and throw
away the rest of the data.  This is also an unbiased estimator of $\mu_x$:
  $$bias(x_1) = E(x_1 - \mu_x) = \mu_x - \mu_x = 0$$
This example illustrates a general principle: there is rarely exactly
one unbiased estimator.  There are either none, or many.
:::

::: example
**An unbiased estimator of the variance**

The sample variance is an unbiased estimator of the population 
variance:
  $$E(s_x^2) = \sigma_x^2 = var(x_i)$$
This is not hard to prove, but I will skip it for now.
:::

If there are multiple unbiased estimators, we need to consider a 
second criterion. One option is to consider the ***variance*** of the
estimator:
  $$var(s) = E[(s-(E(s))^2]$$
Low variance is better than high variance. 

::: example
**The variance of the sample mean and an alternative estimator **

In our previous example, we found two unbiased estimators for the
mean, the sample average $\bar{x}$ and the first observation $x_1$.

The variance of the sample average is:
  $$var(\bar{x}) = \sigma^2/n$$
and the variance of the "first observation estimator: is:
  $$var(x_1) = \sigma^2$$
Since $\sigma^2/n < \sigma^2$, the sample average $\bar{x}$ has
lower variance than the first observation estimator $x_i$.

In fact, we can prove that $\bar{x}$ is the 
***minimum variance unbiased estimator*** of $\mu_x$, i.e.,
the unbiased estimator with the lowest variance.
:::

Unfortunately, once we move beyond the simple case of estimating 
the population mean, we run into several complications:

- An unbiased estimator may not exist for a particular parameter, 
  in which case there is no minimum variance unbiased 
  estimator.
- There may be a slightly biased estimator that has much lower variance
  than any unbiased estimator. In fact, we can find examples
  in which the biased estimator *always* has smaller error 
  than any unbiased estimator.

This suggests that we need a criterion that allows for a trade-off
between variance and bias.

The ***mean squared error*** of the estimator is defined as:
$$MSE(s) = E[(s-\theta)^2]$$
We can do a little math and show that:
$$MSE(s) = var(s) + [bias(s)]^2$$
The MSE criterion allows us to choose a biased estimator with low variance
over an unbiased estimator with high variance, and also allows us to choose
between biased estimators when no unbiased estimator exists.

::: example
**The MSE of the sample mean and an alternative estimator **

The mean squared error of the sample average is:
  $$MSE(\bar{x}) = var(\bar{x}) + [bias(\bar{x})]^2 = \frac{\sigma_x^2}{n} + 0^2 = \frac{\sigma_x^2}{n}$$
and the mean squared error of the first observation estimator is:
  $$MSE(x_1) = \sigma_x^2$$
The sample average is the preferred estimator by the MSE criterion,
so in this case we get the same result as applying the MVUE criterion.
:::

The sample median is an example of a biased estimator for the population
median. 

::: example
**The sample median is a biased estimator**

Consider a simple example in which $x_i \sim Bernoulli(0.6)$ and $n = 1$.
Then the population median is the most likely value for $x_i$:
  $$m_x = 1$$
and the sample median is the observed value for $x_i$:
  $$\hat{m}_x = x_1$$
The mean of $\hat{m}_x$ is:
  $$E(\hat{m}_x) = E(x_1) = p$$
and so the bias is 
  $$E(\hat{m}_x - m_x) = p - 1$$
Now this is a very simple example, but the basic idea applies more generally:
there is usually[^2] no unbiased estimator for the population median
or any other population quantile. 
:::

[^2]: There are exceptions. For example, if the population median and 
  the population mean are identical, then the sample average is an 
  unbiased estimator of both.


::: example
**A biased estimator with lower MSE than the sample average**

Here's an example of a biased estimator that has lower MSE than any unbiased
estimator.  Suppose that we know that $x_i \sim N(\mu_x,\sigma_x^2)$ and
that $\mu_x \geq 0$.  

The sample average $\bar{x}$ is a good estimator for $\mu_x$, 
but since we know $\mu_x \geq 0$ we can do better. 
Let 
  $$s = max(\bar{x},0)$$
Intuitively, this will be a better estimator since it is identical 
to $\bar{x}$ whenever $\bar{x} \geq 0$ and strictly closer to $\mu_x$ 
whenever $\bar{x} < 0$. 

With a little bit of math we can show that this alternative estimator 
is biased:
$$E(s) > E(\bar{x}) = \mu_x$$
but has lower MSE than the (unbiased) sample average:
$$MSE(s) < MSE(\bar{x})$$
:::

### Standard errors

Parameter estimates are typically reported along with their
***standard errors***.  The standard error of a statistic is
an estimate of its standard deviation.

::: example
**The standard error of the average**

We have shown that the sample average provides a good estimate
of the population mean, and that its variance is:
  $$var(\bar{x}) = \frac{\sigma_x^2}{n} = \frac{var(x_i)}{n}$$
Since $s_x^2$ is an unbiased estimator of $var(x_i)$ we can use
it to construct an unbiased estimator of $var(\bar{x})$:
  $$E\left(\frac{s_x^2}{n}\right) = \frac{E(s_x^2)}{n} = \frac{var(x_i)}{n} = var(\bar{x})$$


We might also want to estimate the standard deviation of $\bar{x}$. A natural
approach would be to take the square root of the estimator above, yielding:
  $$se(\bar{x}) = \frac{s_x}{\sqrt{n}}$$
This is the conventional formula for the standard error of the sample
average, and is typically reported next to the sample average.
:::

In general, the standard error of a statistic is an estimator of the statistic's
standard deviation. It is not exactly unbiased, but its bias is typically small and it has some other useful properties that we will use later.

## Asymptotics

So far, we have described statistics and estimators in terms
of their probability distribution and the mean, variance
and mean squared error associated with that probability 
distribution. 

We are able to do this fairly easy with both sample averages 
and sample frequencies (which are also sample averages)
because they are sums. Unfortunately, this is not so easy 
with other statistics (e.g. standard errors, medians, 
percentiles, etc.) that are nonlinear functions of the data.

In order to deal with those statistics, we need to construct
approximations based on the ***asymptotic*** properties
of the statistics.  Asymptotic properties are properties 
that hold approximately, with the approximation getting 
closer and closer to the truth as the sample size gets 
larger.  

Properties that hold exactly for any sample size 
are sometimes called ***exact*** or ***finite sample***
properties. All of the results we have discussed
so far are finite sample results.

We will state three main asymptotic results, the law of large
numbers, the central limit theorem, and Slutsky's theorem. All
three rely on relatively sophisticated math, so I will not
expect you to do much with them.  Please focus on the intuition
and interpretation and don't worry too much about the math.

### The law of large numbers

The ***law of large numbers*** (LLN) says that for a large enough random
sample, the sample average is almost identical to the corresponding
population mean.  

In order to state the LLN, we need to introduce some concepts. Consider
a data set $D_n$ of size $n$, and let $w_n$ be some statistic
calculated from $D_n$. We say that $w_n$ ***converges in probability*** 
to some constant $c$ if:
  $$\lim_{n \rightarrow \infty} \Pr( |w_n - c| < \epsilon) = 1$$
for any positive number $\epsilon > 0$.

Intiutively, what this means is that for a sufficiently large $n$ 
(the $\lim_{n \rightarrow \infty}$ part), $w_n$ is almost certainly
(the $\Pr(\cdot) = 1$ part) very close to $c$
(the $|w_n-c| < \epsilon$ part).

We have a compact way of writing convergence in probability:
  $$w_n \rightarrow^p c$$
means that $w_n$ converges in probability to $c$. 

Having defined our terms we can now state the law of large numbers.

::: fyi
**LAW OF LARGE NUMBERS**: Let $\bar{x}_n$ be the sample average 
from a random sample of size $n$ on the random variable $x_i$ with
mean $E(x_i) = \mu_x$. Then
  $$\bar{x}_n \rightarrow^p \mu_x$$
:::

::: example
**The LLN in the economy**

The law of large numbers is extremely powerful and important, as it
is the basis for the gambling industry, the insurance industry,
and much of the banking industry. 

A casino works by taking in a *large* number of *independent* small
bets. As we have seen for the case of roulette, these bets
have a small house advantage, so their average benefit to 
the casino is positive. The casino can lose any bet, but the 
LLN virtually guarantees that the gains will outweigh the 
losses as long as the casino takes in a large enough number
of independent bets.

An insurance company works almost the same as a casino. Each of
us faces a small risk of a catastrophic cost: a house that
burns down, a car accident leading to serious injury, etc.
Insurance companies collect a little bit of money from each
of us, and pay out a lot of money to the small number of 
people who have claims. Although the context is quite different,
the underlying economics are identical to those of a casino:
the insurance company prices its products so that its revenues 
exceed its expected payout, and takes on a large number of
independent risks.

Sometimes insurance companies do lose money, and even go 
bankrupt. The usual cause of this is a big systemic 
event like a natural disaster, pandemic or financial crisis
that affects everyone.  Here the independence needed for the LLN
does not apply.
:::


### The central limit theorem

The ***Central Limit Theorem (CLT)*** is an even more powerful result.
It roughly says that for a sufficiently large sample size we can
approximate the entire probability distribution of 
$\bar{x}$ by a normal distribution.

As with the LLN, we need to invest in some terminology before we can
state the CLT.  Let $w_n$ be a statistic calculated from $D_n$ and 
let $F_n(\cdot)$ be its CDF. We say that $w_n$ 
***converges in distribution*** to a random variable $w$ with CDF $F(\cdot)$, or 
  $$w_n \rightarrow^D w$$
if
  $$\lim_{n \rightarrow \infty} |F_n(a) - F(a)| = 0$$
for every $a \in \mathbb{R}$.

Convergence in distribution means we can approximate the actual CDF
$F_n(\cdot)$ of $w_n$ with its limit $F(\cdot)$.  As with most approximations,
this is useful whenever $F_n(\cdot)$ is difficult to calculate and $F(\cdot)$
is easy to calculate. 

::: fyi
**CENTRAL LIMIT THEOREM**: Let $\bar{x}_n$ be the sample average 
from a random sample of size $n$ on the random variable $x_i$ with
mean $E(x_i) = \mu_x$ and variance $var(x_i) = \sigma_x^2$. Then
  $$z_n \rightarrow^D z \sim N(0,1)$$
:::

What does the central limit theorem mean?

  - Fundamentally, it means that if $n$ is big enough then the probability
    distribution of $\bar{x}_n$ is approximately normal 
    *no matter what the original distribution of $x_i$ looks like.*
  - In order for the CLT to apply, we need to rescale $\bar{x}_n$
    so that it has zero mean (by subtracting $E(\bar{x}_n) = \mu_x$) 
    and constant variance as $n$ increases (by dividing by 
    $sd(\bar{x}_n) = \sigma_x/\sqrt{n}$)).  That rescaled sample
    average is $z_n$.  
  - In practice, we don't usually know $\mu_x$ or $\sigma_x$ so 
    we can't calculate $z_n$ from data. Fortunately, there are some
    tricks for getting around this problem that we will talk
    about later.

### Consistent estimation

The law of large numbers and central limit theorem apply to the sample
mean, but we are interested in other estimators as well.

In general, we say that the statistic $s$ is a ***consistent*** 
estimator of a parameter $\theta$ if:
$$s \rightarrow^P \theta$$
It will turn out that most of the statistics we use are consistent 
estimators of the thing we typically use them to estimate. 

The key to this property is a result called ***Slutsky's theorem***.
Slutsky's theorem roughly says that if the law of large numbers
and central limit theorem applies to a statistic $s_n$, it also
applies to $g(s_n)$ for any continuous function $g(\cdot)$.

::: fyi
**SLUTSKY THEOREM**: Let $g(\cdot)$ be a continuous function. Then:
  $$w_n \rightarrow^p c \implies g(w_n) \rightarrow^p g(c)$$
and:
  $$w_n \rightarrow^D w \implies g(w_n) \rightarrow^D g(w)$$
:::

What is the importance of Slutsky's theorem?  Most commonly used statistics
can be written as continuous functions of a sample average (or several 
sample averages). Slutsky's theorem

  - extends the LLN to these statistics 
    - Most commonly used statistics are consistent estimators of 
      the corresponding population parameter.
  - extends the CLT to these statistics
    - Most commonly used statistics are also asymptotically normal.

The math needed to make full use of Slutsky's theorem is beyond the scope
of this course, so all I am asking here is for you to know that it can be
used for this purpose.
